{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data mining report**\n",
    "Lukas Kostka and Natalie Ruzickova\n",
    "28.3.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "This section of the notebook begins by importing the **`pandas`** library, a powerful tool for data manipulation and analysis in Python. The code then specifies the file path for the dataset 'bank-full.csv', which is presumed to contain data related to a bank's marketing campaign.\n",
    "\n",
    "Using the **`pd.read_csv`** function, the dataset is loaded into a pandas DataFrame. This function is highly versatile and capable of handling various delimiters; here, it's instructed to use a semicolon (**`sep=';'`**) based on the dataset's structure. Once loaded, the first five rows of the DataFrame are displayed using the **`.head()`** method, providing a quick glance at the dataset's features and initial rows.\n",
    "\n",
    "#### Dataset Overview\n",
    "\n",
    "The dataset comprises several columns (21 in total), reflecting different attributes related to bank clients and the marketing campaign. Key columns include:\n",
    "\n",
    "-   **`age`**: The client's age.\n",
    "\n",
    "-   **`job`**: Job type of the client.\n",
    "\n",
    "-   **`marital`**: Marital status of the client.\n",
    "\n",
    "-   **`education`**: Education level of the client.\n",
    "\n",
    "-   **`default`**: Indicates if the client has credit in default.\n",
    "\n",
    "-   **`housing`**: Indicates if the client has a housing loan.\n",
    "\n",
    "-   **`loan`**: Indicates if the client has a personal loan.\n",
    "\n",
    "-   Additional columns related to the marketing campaign's context (**`contact`**, **`month`**, **`day_of_week`**, **`campaign`**, **`pdays`**, **`previous`**, **`poutcome`**) and economic context (**`emp.var.rate`**, **`cons.price.idx`**, **`cons.conf.idx`**, **`euribor3m`**, **`nr.employed`**).\n",
    "\n",
    "#### EXPLANATION OF COLUMNS\n",
    "-   **`poutcome`**: This stands for \"previous outcome\" and refers to the outcome of the previous marketing campaign. It indicates whether the client subscribed to a term deposit in the previous marketing campaign. Possible values could include \"success\" if the client subscribed, \"failure\" if the client did not subscribe, or \"nonexistent\" if the client was not contacted previously.\n",
    "\n",
    "-   **`emp.var.rate`**: This refers to the employment variation rate. It represents the quarterly indicator of the employment variation rate. This rate reflects the changes in the level of employment in the economy over time. A higher positive value indicates an increase in employment, while a negative value indicates a decrease.\n",
    "\n",
    "-   **`cons.price.idx`**: This stands for the consumer price index. It measures the changes in the price level of a market basket of consumer goods and services purchased by households. It is often used as an indicator of inflation.\n",
    "\n",
    "-   **`cons.conf.idx`**: This refers to the consumer confidence index. It measures consumers' confidence in the economy. A higher value indicates higher confidence, which often correlates with increased spending and economic growth, while a lower value indicates lower confidence, which may lead to decreased spending and economic slowdown.\n",
    "\n",
    "-   **`euribor3m`**: This stands for the Euro Interbank Offered Rate (EURIBOR) over a 3-month period. It is the interest rate at which European banks offer to lend funds to one another in the euro market. It is a key benchmark interest rate used in the European financial system.\n",
    "\n",
    "-   **`nr.employed`**: This represents the number of employees. It indicates the total number of people employed in the economy. Changes in this number can reflect changes in the labor market and overall economic conditions.\n",
    "\n",
    "-   **`y`**: The target variable, indicating whether the client subscribed to a term deposit (**`yes`** or **`no`**).\n",
    "\n",
    "#### Evaluation of Initial Exploration\n",
    "\n",
    "The initial data loading and exploration are crucial steps in any data analysis project. They allow for:\n",
    "\n",
    "-   Verifying that the dataset has been loaded correctly into the DataFrame.\n",
    "\n",
    "-   Gaining an immediate understanding of the dataset structure, including column names, data types, and the presence of any obvious data issues such as missing values.\n",
    "\n",
    "-   Setting the stage for more in-depth data cleaning and exploratory data analysis.\n",
    "\n",
    "This code block is efficiently written to accomplish these objectives with minimal complexity. The use of **`pd.read_csv`** with appropriate parameters ensures the dataset is loaded as expected, and the use of **`df.head()`** provides an essential first look at the data to inform subsequent analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   job             marital    education             default   housing   \\\n",
       "0    56  housemaid       married    basic.4y              no        no         \n",
       "1    57  services        married    high.school           unknown   no         \n",
       "2    37  services        married    high.school           no        yes        \n",
       "3    40  admin.          married    basic.6y              no        no         \n",
       "4    56  services        married    high.school           no        no         \n",
       "\n",
       "   loan      contact     month   day_of_week   ...  campaign   pdays   \\\n",
       "0  no        telephone   may     mon           ...          1     999   \n",
       "1  no        telephone   may     mon           ...          1     999   \n",
       "2  no        telephone   may     mon           ...          1     999   \n",
       "3  no        telephone   may     mon           ...          1     999   \n",
       "4  yes       telephone   may     mon           ...          1     999   \n",
       "\n",
       "   previous   poutcome     emp.var.rate   cons.price.idx   cons.conf.idx   \\\n",
       "0          0  nonexistent            1.1           93.994           -36.4   \n",
       "1          0  nonexistent            1.1           93.994           -36.4   \n",
       "2          0  nonexistent            1.1           93.994           -36.4   \n",
       "3          0  nonexistent            1.1           93.994           -36.4   \n",
       "4          0  nonexistent            1.1           93.994           -36.4   \n",
       "\n",
       "   euribor3m   nr.employed    y  \n",
       "0       4.857        5191.0  no  \n",
       "1       4.857        5191.0  no  \n",
       "2       4.857        5191.0  no  \n",
       "3       4.857        5191.0  no  \n",
       "4       4.857        5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path of the dataset\n",
    "file_path = 'bank-full.csv'\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(r\"C:\\Users\\natal\\OneDrive\\Plocha\\vš\\6.semestr\\HAN\\06data mining\\datamininglukas\\Data Mining\\bank-full.csv\", sep=';')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the initial data loading and exploration, this segment of the notebook focuses on data preprocessing, specifically the standardization of numerical columns. It begins by importing **`StandardScaler`** from **`sklearn.preprocessing`**, a component of the scikit-learn library dedicated to preprocessing input data.\n",
    "\n",
    "A **`StandardScaler`** instance is created with default settings. This scaler standardizes features by removing the mean and scaling to unit variance, a common requirement for many machine learning estimators to perform optimally.\n",
    "\n",
    "The code then identifies numerical columns in the dataset (**`df`**) by selecting those of types **`int64`** and **`float64`**. This selection is stored in **`num_cols`**, which is subsequently used to apply the standardization only to these columns. The **`fit_transform`** method of the **`StandardScaler`** is employed to compute the mean and standard deviation for each column, then standardize the values.\n",
    "\n",
    "Finally, the standardized values are reassigned to the respective columns in the DataFrame, and the first few rows of the modified DataFrame are displayed using **`df.head()`** to confirm the changes.\n",
    "\n",
    "#### Evaluation of Data Standardization\n",
    "\n",
    "Standardizing the data is a vital step in the preprocessing phase, especially when employing algorithms that are sensitive to the scale of input features, such as logistic regression, support vector machines, and k-nearest neighbors.\n",
    "\n",
    "-   **Advantages**:\n",
    "\n",
    "    -   Enhances numerical stability and the performance of the algorithm.\n",
    "\n",
    "    -   Ensures that features contribute equally to the model's learning process, preventing bias towards features with naturally larger scales.\n",
    "\n",
    "    -   Facilitates the convergence of gradient descent algorithms by providing a uniform scale.\n",
    "\n",
    "-   **Considerations**:\n",
    "\n",
    "    -   It's crucial to fit the scaler only on the training data and not the test data to prevent data leakage. However, this code segment does not explicitly differentiate between training and test sets, which might be addressed in subsequent steps.\n",
    "\n",
    "    -   While standardization is generally beneficial, it might not be necessary or could be counterproductive for some algorithms that are scale-invariant or where the original scale of the data has meaning.\n",
    "\n",
    "This code block efficiently performs the standardization of numerical columns, setting a solid foundation for any subsequent modeling efforts. The use of **`StandardScaler`** and the careful selection of numerical columns for this process exemplify good practices in data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.628993</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.290186</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002309</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   job             marital    education             default   \\\n",
       "0  1.533034  housemaid       married    basic.4y              no         \n",
       "1  1.628993  services        married    high.school           unknown    \n",
       "2 -0.290186  services        married    high.school           no         \n",
       "3 -0.002309  admin.          married    basic.6y              no         \n",
       "4  1.533034  services        married    high.school           no         \n",
       "\n",
       "   housing   loan      contact     month   day_of_week   ...  campaign   \\\n",
       "0  no        no        telephone   may     mon           ...  -0.565922   \n",
       "1  no        no        telephone   may     mon           ...  -0.565922   \n",
       "2  yes       no        telephone   may     mon           ...  -0.565922   \n",
       "3  no        no        telephone   may     mon           ...  -0.565922   \n",
       "4  no        yes       telephone   may     mon           ...  -0.565922   \n",
       "\n",
       "     pdays   previous   poutcome     emp.var.rate   cons.price.idx   \\\n",
       "0  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "1  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "2  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "3  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "4  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "\n",
       "   cons.conf.idx   euribor3m   nr.employed    y  \n",
       "0        0.886447     0.71246       0.33168  no  \n",
       "1        0.886447     0.71246       0.33168  no  \n",
       "2        0.886447     0.71246       0.33168  no  \n",
       "3        0.886447     0.71246       0.33168  no  \n",
       "4        0.886447     0.71246       0.33168  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook introduces data visualization, focusing on the distribution of the target variable **`y`** within the dataset. It employs the seaborn library, a popular Python visualization library based on matplotlib that provides a high-level interface for drawing attractive statistical graphics.\n",
    "\n",
    "The code snippet starts with importing the seaborn library as **`sns`**, following the convention. It then uses **`sns.countplot`** to create a count plot, which is a type of bar plot that shows the counts of observations in each categorical bin using bars.\n",
    "\n",
    "The **`countplot`** function is directed to plot the distribution of the target variable **`y`** (**`yes`** or **`no`**) from the DataFrame **`df`**. Additional matplotlib functions are used to set the x-axis label (**`plt.xlabel('y')`**), the y-axis label (**`plt.ylabel('Count')`**), and the title of the plot (**`plt.title('Number of \"yes\" and \"no\" in column y')`**).\n",
    "\n",
    "#### Evaluation of the Visualization\n",
    "\n",
    "This visualization is crucial for understanding the balance or imbalance in the dataset regarding the target variable. The output numbers, **`no: 36548`** and **`yes: 4640`**, indicate a significant imbalance between the two classes, with a much higher number of **`no`** responses compared to **`yes`**.\n",
    "\n",
    "-   **Advantages**:\n",
    "\n",
    "    -   Quickly highlights the distribution of the target variable, which is essential for choosing the correct modeling approach and evaluating model performance.\n",
    "\n",
    "    -   The imbalance illustrated by the plot informs the need for potential strategies during model training, such as oversampling, undersampling, or using specific evaluation metrics that account for imbalance.\n",
    "\n",
    "-   **Considerations**:\n",
    "\n",
    "    -   Given the imbalance shown, care must be taken in model evaluation. Metrics like accuracy might be misleading; alternative metrics such as precision, recall, F1 score, or ROC AUC may provide more insight.\n",
    "\n",
    "    -   The plot effectively communicates the need for potential preprocessing strategies to address class imbalance, which could include techniques like SMOTE (Synthetic Minority Over-sampling Technique) or adjusting class weights in model training.\n",
    "\n",
    "Overall, this visualization step is effectively implemented, offering immediate insights into the class distribution of the target variable. It sets the stage for informed decision-making in subsequent data preprocessing, model selection, and evaluation strategy development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCf0lEQVR4nO3dfVhUdf7/8deIAt404z1I4n2rYoqKimxlmgQqlm7YaprifRpqwqZI6+LN1lq6FeZNZu2KlraaZTeSGmJqJWXRkvduN5qmcmMKo6igML8/+nJ+jnhzRHTAno/rOlee83nPmfc5MM2Lc86csTgcDocAAABwVRVc3QAAAEB5QGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAkrR5s2bZbFYtHr1ale3YkpGRob69eunWrVqyWKxKD4+3tUt3TYaNWqkoUOHurqNUjF06FA1atTI1W1ckcVi0fTp013dBn4HCE0odxISEmSxWOTp6akjR44UG+/atavuvvtuF3RW/kRFRWnDhg2KjY3Vm2++qR49elyx1mKxKCEhQdJvgcDVb1JFvwfS/w+rBw8edGlPJXGr9+vQoUPVtWtXSdL06dPLdBgCypqKrm4AKKm8vDw9//zzmjdvnqtbKbc2bdqkPn366Omnn3Z1KyjDXn/9dRUWFrq6DcDlONKEcqtt27Z6/fXXdfToUVe3csvl5uaWynoyMzNVvXr1UlkXbl+VKlWSh4eHq9sAXI7QhHLrmWeeUUFBgZ5//vmr1h08eNDpFMjFLr0WYvr06bJYLPrf//6nxx9/XDabTXXq1NHf/vY3ORwOHT58WH369JHVapW3t7defPHFyz5nQUGBnnnmGXl7e6tq1ap6+OGHdfjw4WJ1X331lXr06CGbzaYqVaro/vvv1xdffOFUU9TTnj17NHDgQNWoUUP33nvvVbf5p59+0qOPPqqaNWuqSpUq6ty5sxITE43xolNbDodDCxYskMViMU51Xa+ffvpJFotFL7/8crGxbdu2yWKx6O233zaWHTlyRMOHD5eXl5c8PDzUqlUr/fvf/y722Hnz5qlVq1aqUqWKatSooQ4dOmjFihUl6rHIzz//rCeffFLNmzdX5cqVVatWLT366KPFTusV7Z8vvvhC0dHRqlOnjqpWrao//elPysrKcqp1OBx69tlnVb9+fVWpUkXdunXT7t27b6jPkvQhSQsXLlSrVq3k4eEhHx8fRUZGKjs7+4b7uPSapqLX1D//+U8tXrxYTZs2lYeHhzp27Kivv/7a1Dqzs7MVFRWlRo0aycPDQ/Xr19eQIUN0/PhxoyYzM1MjRoyQl5eXPD095e/vr6VLl153v0WKXksXs1gsGjdunN555x35+fmpcuXKCgoK0s6dOyVJr732mpo1ayZPT0917dq12O9K0eUAe/bsUbdu3VSlShXdeeedmj179jX7vP/+++Xv73/ZsebNmys0NPSa68CtRWhCudW4cWMNGTLkphxt6t+/vwoLC/X8888rMDBQzz77rOLj4/Xggw/qzjvv1AsvvKBmzZrp6aef1tatW4s9/rnnnlNiYqJiYmI0YcIEJSUlKTg4WGfPnjVqNm3apC5dushut2vatGn6xz/+oezsbD3wwAPavn17sXU++uijOnPmjP7xj39o1KhRV+w9IyNDf/zjH7VhwwY9+eSTeu6553Tu3Dk9/PDDWrNmjSSpS5cuevPNNyVJDz74oN58801j/no1adJE99xzj5YvX15sbPny5brjjjvUp08fo7fOnTtr48aNGjdunObOnatmzZppxIgRThehv/7665owYYL8/PwUHx+vGTNmqG3btvrqq69K1GORr7/+Wtu2bdOAAQP0yiuvaMyYMUpOTlbXrl115syZYvXjx4/Xd999p2nTpmns2LH66KOPNG7cOKeauLg4/e1vf5O/v7/mzJmjJk2aKCQkpNSOBprtY/r06YqMjJSPj49efPFFhYeH67XXXlNISIjOnz9far1cbMWKFZozZ46eeOIJPfvsszp48KAeeeSRaz7f6dOndd9992nevHkKCQnR3LlzNWbMGO3bt0+//PKLJOns2bPq2rWr3nzzTQ0aNEhz5syRzWbT0KFDNXfu3FLdjs8++0x/+ctfFBERoenTp2vv3r3q3bu3FixYoFdeeUVPPvmkJk2apJSUFA0fPrzY40+ePKkePXrI399fL774olq0aKGYmBitW7fuqs87ePBg7dixQ7t27XJa/vXXXxt/uKGMcQDlzJIlSxySHF9//bXjxx9/dFSsWNExYcIEY/z+++93tGrVypg/cOCAQ5JjyZIlxdYlyTFt2jRjftq0aQ5JjtGjRxvLLly44Khfv77DYrE4nn/+eWP5yZMnHZUrV3ZEREQYyz799FOHJMedd97psNvtxvJVq1Y5JDnmzp3rcDgcjsLCQsddd93lCA0NdRQWFhp1Z86ccTRu3Njx4IMPFuvpscceM7V/Jk6c6JDk+Oyzz4xlp06dcjRu3NjRqFEjR0FBgdP2R0ZGmlrv1bz22msOSY69e/cay/Lz8x21a9d22j8jRoxw1KtXz3H8+HGnxw8YMMBhs9kcZ86ccTgcDkefPn2cfoalpWj9F0tJSXFIcixbtsxYVvQ7Fhwc7PTziYqKcri5uTmys7MdDofDkZmZ6XB3d3eEhYU51T3zzDMOSU7bXhLX20dISIjTz3f+/PkOSY5///vfN9RHRESEo2HDhsZ80WuqVq1ajhMnThjLP/jgA4ckx0cffXTV9cXFxTkkOd57771iY0XbGR8f75DkeOutt4yx/Px8R1BQkKNatWpOr69LX8eX9luk6LV0MUkODw8Px4EDB4xlRb/P3t7eTs8TGxvrkORUe//99xf7/cnLy3N4e3s7wsPDr7ofsrOzHZ6eno6YmBin5RMmTHBUrVrVcfr06as+HrceR5pQrjVp0kSDBw/W4sWLdezYsVJb78iRI41/u7m5qUOHDnI4HBoxYoSxvHr16mrevLl++umnYo8fMmSI7rjjDmO+X79+qlevnj7++GNJUlpamr7//nsNHDhQv/76q44fP67jx48rNzdX3bt319atW4tdeDtmzBhTvX/88cfq1KmT0ym8atWqafTo0Tp48KD27Nljbidchz//+c/y9PR0Otq0YcMGHT9+3Phr2eFw6N1339VDDz0kh8NhbPPx48cVGhqqnJwcffvtt5J+27e//PKL6VM9ZlWuXNn49/nz5/Xrr7+qWbNmql69uvHcFxs9erTT6Zz77rtPBQUF+vnnnyVJGzduVH5+vsaPH+9UN3HixFLt22wfEydOVIUK//9/66NGjZLVanU6NVua+vfvrxo1ajj1Jemyr4mLvfvuu/L399ef/vSnYmNF2/nxxx/L29tbjz32mDFWqVIlTZgwQadPn9aWLVtKYxMkSd27d3c6nRcYGChJCg8Pd3odFy2/dPuqVavmdFTI3d1dnTp1uuZ+sNls6tOnj95++205HA5Jv53aX7lypfr27auqVave0Hah9BGaUO5NnTpVFy5cuOa1TdejQYMGTvM2m02enp6qXbt2seUnT54s9vi77rrLad5isahZs2bG9RDff/+9JCkiIkJ16tRxmt544w3l5eUpJyfHaR2NGzc21fvPP/+s5s2bF1vesmVLY7y0Va9eXQ899JDTNUfLly/XnXfeqQceeECSlJWVpezsbC1evLjYNg8bNkzSb9ewSFJMTIyqVaumTp066a677lJkZGSxa71K4uzZs4qLi5Ovr688PDxUu3Zt1alTR9nZ2cX2t1T896AoIBT9zIv25aU/7zp16jiFiRtlto9Lf+7u7u5q0qTJTfmZm+nrSn788cdr3hbk559/1l133eUUAqWb83t8ude7JPn6+l52+aXbV79+/WLXStWoUeOa+0H67Q+sQ4cO6bPPPpP0WwDOyMjQ4MGDr28jcEtwywGUe02aNNHjjz+uxYsXa8qUKcXGr3SBc0FBwRXX6ebmZmqZJOMvxOtRdBRpzpw5atu27WVrqlWr5jR/8VGSsmjIkCF65513tG3bNrVu3VoffvihnnzySeNNr2ibH3/8cUVERFx2HW3atJH02xvj/v37tXbtWq1fv17vvvuuFi5cqLi4OM2YMaPEPY4fP15LlizRxIkTFRQUJJvNJovFogEDBlz2I/Wl+TO/EWWlj0uV1b6u9zV/pe0wu303sh9CQ0Pl5eWlt956S126dNFbb70lb29vBQcHX/OxuPUITbgtTJ06VW+99ZZeeOGFYmNFf/1e+imim/XXt/T/jyQVcTgc+uGHH4xQ0LRpU0mS1Wot9f85NmzYUPv37y+2fN++fcb4zdCjRw/VqVNHy5cvV2BgoM6cOeP013KdOnV0xx13qKCgwNQ2V61aVf3791f//v2Vn5+vRx55RM8995xiY2Pl6elZoh5Xr16tiIgIp089njt3rsSfMCval99//72aNGliLM/KyjJ1lKG0FPWxf/9+pz7y8/N14MCBMvcG3LRp02IXP1+qYcOG2rFjhwoLC52ONpn5Pa5Ro8Zlf6Y38zVfUm5ubho4cKASEhL0wgsv6P3339eoUaOuGMTgWpyew22hadOmevzxx/Xaa68pPT3dacxqtap27drFPuW2cOHCm9bPsmXLdOrUKWN+9erVOnbsmHr27ClJCggIUNOmTfXPf/5Tp0+fLvb4y32c3KxevXpp+/btSklJMZbl5uZq8eLFatSokfz8/Eq87qupWLGiHnvsMa1atUoJCQlq3bq1ERKl394cwsPD9e677172DfPibf7111+dxtzd3eXn5yeHw3FDnwRzc3Mr9tf/vHnzrnrU8WqCg4NVqVIlzZs3z2m9t/rraIKDg+Xu7q5XXnnFqY9//etfysnJUVhY2C3t51rCw8P13XffGZ/mvFhR/7169VJ6erpWrlxpjF24cEHz5s1TtWrVdP/9919x/U2bNlVOTo527NhhLDt27Nhln68sGDx4sE6ePKknnnhCp0+f5lNzZRhHmnDb+Otf/6o333xT+/fvV6tWrZzGRo4cqeeff14jR45Uhw4dtHXrVv3vf/+7ab3UrFlT9957r4YNG6aMjAzFx8erWbNmxq0CKlSooDfeeEM9e/ZUq1atNGzYMN155506cuSIPv30U1mtVn300Ucleu4pU6bo7bffVs+ePTVhwgTVrFlTS5cu1YEDB/Tuu+8Wu0akNA0ZMkSvvPKKPv3008se9Xv++ef16aefKjAwUKNGjZKfn59OnDihb7/9Vhs3btSJEyckSSEhIfL29tY999wjLy8v7d27V/Pnz1dYWJjThbnXq3fv3nrzzTdls9nk5+enlJQUbdy4UbVq1SrR+urUqaOnn35as2bNUu/evdWrVy/997//1bp164pd/3Yz1alTR7GxsZoxY4Z69Oihhx9+WPv379fChQvVsWPHMvcmPGnSJK1evVqPPvqohg8froCAAJ04cUIffvihFi1aJH9/f40ePVqvvfaahg4dqtTUVDVq1EirV6/WF198ofj4+Kv+HgwYMEAxMTH605/+pAkTJujMmTN69dVX9Yc//OGyF/y7Wrt27XT33XfrnXfeUcuWLdW+fXtXt4QrIDThttGsWTM9/vjjl735XVxcnLKysrR69WqtWrVKPXv21Lp161S3bt2b0sszzzyjHTt2aNasWTp16pS6d++uhQsXqkqVKkZN165dlZKSor///e+aP3++Tp8+LW9vbwUGBuqJJ54o8XN7eXlp27ZtiomJ0bx583Tu3Dm1adNGH3300U0/4hAQEKBWrVpp7969GjRo0GV72759u2bOnKn33ntPCxcuVK1atdSqVSunkPXEE09o+fLleumll3T69GnVr19fEyZM0NSpU2+ov7lz58rNzU3Lly/XuXPndM8992jjxo03dBPBZ599Vp6enlq0aJERCD/55JNbfnRn+vTpqlOnjubPn6+oqCjVrFlTo0eP1j/+8Q9VqlTplvZyLdWqVdNnn32madOmac2aNVq6dKnq1q2r7t27q379+pJ+u4Zv8+bNmjJlipYuXSq73a7mzZtryZIl1/wi5Fq1amnNmjWKjo7W5MmT1bhxY82aNUvff/99mQxN0m9/cEyePJkLwMs4i8PVV+wBuK20a9dONWvWVHJysqtbAcqNuXPnKioqSgcPHiz2aT6UHVzTBKDUfPPNN0pLS9OQIUNc3QpQbjgcDv3rX//S/fffT2Aq4zg9B+CG7dq1S6mpqXrxxRdVr1499e/f39UtAWVebm6uPvzwQ3366afauXOnPvjgA1e3hGsgNAG4YatXr9bMmTPVvHlzvf322yW+JQDwe5KVlaWBAweqevXqeuaZZ/Twww+7uiVcA9c0AQAAmMA1TQAAACYQmgAAAEzgmqZSUlhYqKNHj+qOO+644vceAQCAssXhcOjUqVPy8fG55s1/CU2l5OjRo8W+ERsAAJQPhw8fNm6ueiWEplJSdEv/w4cPy2q1urgbAABght1ul6+vr6mvaCI0lZKiU3JWq5XQBABAOWPm0houBAcAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATKjo6gZwfQImLXN1C0CZkzpniKtbAPA7wJEmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABNcGppeffVVtWnTRlarVVarVUFBQVq3bp0x3rVrV1ksFqdpzJgxTus4dOiQwsLCVKVKFdWtW1eTJk3ShQsXnGo2b96s9u3by8PDQ82aNVNCQkKxXhYsWKBGjRrJ09NTgYGB2r59+03ZZgAAUD65NDTVr19fzz//vFJTU/XNN9/ogQceUJ8+fbR7926jZtSoUTp27JgxzZ492xgrKChQWFiY8vPztW3bNi1dulQJCQmKi4szag4cOKCwsDB169ZNaWlpmjhxokaOHKkNGzYYNStXrlR0dLSmTZumb7/9Vv7+/goNDVVmZuat2REAAKDMszgcDoerm7hYzZo1NWfOHI0YMUJdu3ZV27ZtFR8ff9nadevWqXfv3jp69Ki8vLwkSYsWLVJMTIyysrLk7u6umJgYJSYmateuXcbjBgwYoOzsbK1fv16SFBgYqI4dO2r+/PmSpMLCQvn6+mr8+PGaMmWKqb7tdrtsNptycnJktVpvYA9cHd89BxTHd88BKKnref8uM9c0FRQU6D//+Y9yc3MVFBRkLF++fLlq166tu+++W7GxsTpz5owxlpKSotatWxuBSZJCQ0Nlt9uNo1UpKSkKDg52eq7Q0FClpKRIkvLz85WamupUU6FCBQUHBxs1AAAAFV3dwM6dOxUUFKRz586pWrVqWrNmjfz8/CRJAwcOVMOGDeXj46MdO3YoJiZG+/fv13vvvSdJSk9PdwpMkoz59PT0q9bY7XadPXtWJ0+eVEFBwWVr9u3bd8W+8/LylJeXZ8zb7fYS7gEAAFAeuDw0NW/eXGlpacrJydHq1asVERGhLVu2yM/PT6NHjzbqWrdurXr16ql79+768ccf1bRpUxd2Lc2aNUszZsxwaQ8AAODWcfnpOXd3dzVr1kwBAQGaNWuW/P39NXfu3MvWBgYGSpJ++OEHSZK3t7cyMjKcaormvb29r1pjtVpVuXJl1a5dW25ubpetKVrH5cTGxionJ8eYDh8+fB1bDQAAyhuXh6ZLFRYWOp32ulhaWpokqV69epKkoKAg7dy50+lTbklJSbJarcYpvqCgICUnJzutJykpybhuyt3dXQEBAU41hYWFSk5Odrq26lIeHh7GrRKKJgAAcPty6em52NhY9ezZUw0aNNCpU6e0YsUKbd68WRs2bNCPP/6oFStWqFevXqpVq5Z27NihqKgodenSRW3atJEkhYSEyM/PT4MHD9bs2bOVnp6uqVOnKjIyUh4eHpKkMWPGaP78+Zo8ebKGDx+uTZs2adWqVUpMTDT6iI6OVkREhDp06KBOnTopPj5eubm5GjZsmEv2CwAAKHtcGpoyMzM1ZMgQHTt2TDabTW3atNGGDRv04IMP6vDhw9q4caMRYHx9fRUeHq6pU6caj3dzc9PatWs1duxYBQUFqWrVqoqIiNDMmTONmsaNGysxMVFRUVGaO3eu6tevrzfeeEOhoaFGTf/+/ZWVlaW4uDilp6erbdu2Wr9+fbGLwwEAwO9XmbtPU3nFfZoA1+E+TQBKqlzepwkAAKAsIzQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwASXhqZXX31Vbdq0kdVqldVqVVBQkNatW2eMnzt3TpGRkapVq5aqVaum8PBwZWRkOK3j0KFDCgsLU5UqVVS3bl1NmjRJFy5ccKrZvHmz2rdvLw8PDzVr1kwJCQnFelmwYIEaNWokT09PBQYGavv27TdlmwEAQPnk0tBUv359Pf/880pNTdU333yjBx54QH369NHu3bslSVFRUfroo4/0zjvvaMuWLTp69KgeeeQR4/EFBQUKCwtTfn6+tm3bpqVLlyohIUFxcXFGzYEDBxQWFqZu3bopLS1NEydO1MiRI7VhwwajZuXKlYqOjta0adP07bffyt/fX6GhocrMzLx1OwMAAJRpFofD4XB1ExerWbOm5syZo379+qlOnTpasWKF+vXrJ0nat2+fWrZsqZSUFHXu3Fnr1q1T7969dfToUXl5eUmSFi1apJiYGGVlZcnd3V0xMTFKTEzUrl27jOcYMGCAsrOztX79eklSYGCgOnbsqPnz50uSCgsL5evrq/Hjx2vKlCmm+rbb7bLZbMrJyZHVai3NXeIkYNKym7ZuoLxKnTPE1S0AKKeu5/27zFzTVFBQoP/85z/Kzc1VUFCQUlNTdf78eQUHBxs1LVq0UIMGDZSSkiJJSklJUevWrY3AJEmhoaGy2+3G0aqUlBSndRTVFK0jPz9fqampTjUVKlRQcHCwUQMAAFDR1Q3s3LlTQUFBOnfunKpVq6Y1a9bIz89PaWlpcnd3V/Xq1Z3qvby8lJ6eLklKT093CkxF40VjV6ux2+06e/asTp48qYKCgsvW7Nu374p95+XlKS8vz5i32+3Xt+EAAKBccfmRpubNmystLU1fffWVxo4dq4iICO3Zs8fVbV3TrFmzZLPZjMnX19fVLQEAgJvI5aHJ3d1dzZo1U0BAgGbNmiV/f3/NnTtX3t7eys/PV3Z2tlN9RkaGvL29JUne3t7FPk1XNH+tGqvVqsqVK6t27dpyc3O7bE3ROi4nNjZWOTk5xnT48OESbT8AACgfXB6aLlVYWKi8vDwFBASoUqVKSk5ONsb279+vQ4cOKSgoSJIUFBSknTt3On3KLSkpSVarVX5+fkbNxesoqilah7u7uwICApxqCgsLlZycbNRcjoeHh3GrhKIJAADcvlx6TVNsbKx69uypBg0a6NSpU1qxYoU2b96sDRs2yGazacSIEYqOjlbNmjVltVo1fvx4BQUFqXPnzpKkkJAQ+fn5afDgwZo9e7bS09M1depURUZGysPDQ5I0ZswYzZ8/X5MnT9bw4cO1adMmrVq1SomJiUYf0dHRioiIUIcOHdSpUyfFx8crNzdXw4YNc8l+AQAAZY9LQ1NmZqaGDBmiY8eOyWazqU2bNtqwYYMefPBBSdLLL7+sChUqKDw8XHl5eQoNDdXChQuNx7u5uWnt2rUaO3asgoKCVLVqVUVERGjmzJlGTePGjZWYmKioqCjNnTtX9evX1xtvvKHQ0FCjpn///srKylJcXJzS09PVtm1brV+/vtjF4QAA4PerzN2nqbziPk2A63CfJgAlVS7v0wQAAFCWEZoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwASXhqZZs2apY8eOuuOOO1S3bl317dtX+/fvd6rp2rWrLBaL0zRmzBinmkOHDiksLExVqlRR3bp1NWnSJF24cMGpZvPmzWrfvr08PDzUrFkzJSQkFOtnwYIFatSokTw9PRUYGKjt27eX+jYDAIDyyaWhacuWLYqMjNSXX36ppKQknT9/XiEhIcrNzXWqGzVqlI4dO2ZMs2fPNsYKCgoUFham/Px8bdu2TUuXLlVCQoLi4uKMmgMHDigsLEzdunVTWlqaJk6cqJEjR2rDhg1GzcqVKxUdHa1p06bp22+/lb+/v0JDQ5WZmXnzdwQAACjzLA6Hw+HqJopkZWWpbt262rJli7p06SLptyNNbdu2VXx8/GUfs27dOvXu3VtHjx6Vl5eXJGnRokWKiYlRVlaW3N3dFRMTo8TERO3atct43IABA5Sdna3169dLkgIDA9WxY0fNnz9fklRYWChfX1+NHz9eU6ZMuWbvdrtdNptNOTk5slqtN7Ibripg0rKbtm6gvEqdM8TVLQAop67n/btMXdOUk5MjSapZs6bT8uXLl6t27dq6++67FRsbqzNnzhhjKSkpat26tRGYJCk0NFR2u127d+82aoKDg53WGRoaqpSUFElSfn6+UlNTnWoqVKig4OBgo+ZSeXl5stvtThMAALh9VXR1A0UKCws1ceJE3XPPPbr77ruN5QMHDlTDhg3l4+OjHTt2KCYmRvv379d7770nSUpPT3cKTJKM+fT09KvW2O12nT17VidPnlRBQcFla/bt23fZfmfNmqUZM2bc2EYDAIByo8yEpsjISO3atUuff/650/LRo0cb/27durXq1aun7t2768cff1TTpk1vdZuG2NhYRUdHG/N2u12+vr4u6wcAANxcZSI0jRs3TmvXrtXWrVtVv379q9YGBgZKkn744Qc1bdpU3t7exT7llpGRIUny9vY2/lu07OIaq9WqypUry83NTW5ubpetKVrHpTw8POTh4WF+IwEAQLnm0muaHA6Hxo0bpzVr1mjTpk1q3LjxNR+TlpYmSapXr54kKSgoSDt37nT6lFtSUpKsVqv8/PyMmuTkZKf1JCUlKSgoSJLk7u6ugIAAp5rCwkIlJycbNQAA4PfNpUeaIiMjtWLFCn3wwQe64447jGuQbDabKleurB9//FErVqxQr169VKtWLe3YsUNRUVHq0qWL2rRpI0kKCQmRn5+fBg8erNmzZys9PV1Tp05VZGSkcSRozJgxmj9/viZPnqzhw4dr06ZNWrVqlRITE41eoqOjFRERoQ4dOqhTp06Kj49Xbm6uhg0bdut3DAAAKHNcGppeffVVSb/dVuBiS5Ys0dChQ+Xu7q6NGzcaAcbX11fh4eGaOnWqUevm5qa1a9dq7NixCgoKUtWqVRUREaGZM2caNY0bN1ZiYqKioqI0d+5c1a9fX2+88YZCQ0ONmv79+ysrK0txcXFKT09X27ZttX79+mIXhwMAgN+nMnWfpvKM+zQBrsN9mgCUVLm9TxMAAEBZRWgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJpQoNDVp0kS//vprseXZ2dlq0qTJDTcFAABQ1pQoNB08eFAFBQXFlufl5enIkSM33BQAAEBZU/F6ij/88EPj3xs2bJDNZjPmCwoKlJycrEaNGpVacwAAAGXFdYWmvn37SpIsFosiIiKcxipVqqRGjRrpxRdfLLXmAAAAyorrCk2FhYWSpMaNG+vrr79W7dq1b0pTAAAAZc11haYiBw4cKO0+AAAAyrQS33IgOTlZzzzzjEaOHKnhw4c7TWbNmjVLHTt21B133KG6deuqb9++2r9/v1PNuXPnFBkZqVq1aqlatWoKDw9XRkaGU82hQ4cUFhamKlWqqG7dupo0aZIuXLjgVLN582a1b99eHh4eatasmRISEor1s2DBAjVq1Eienp4KDAzU9u3bze8QAABwWytRaJoxY4ZCQkKUnJys48eP6+TJk06TWVu2bFFkZKS+/PJLJSUl6fz58woJCVFubq5RExUVpY8++kjvvPOOtmzZoqNHj+qRRx4xxgsKChQWFqb8/Hxt27ZNS5cuVUJCguLi4oyaAwcOKCwsTN26dVNaWpomTpyokSNHasOGDUbNypUrFR0drWnTpunbb7+Vv7+/QkNDlZmZWZJdBAAAbjMWh8PhuN4H1atXT7Nnz9bgwYNLtZmsrCzVrVtXW7ZsUZcuXZSTk6M6depoxYoV6tevnyRp3759atmypVJSUtS5c2etW7dOvXv31tGjR+Xl5SVJWrRokWJiYpSVlSV3d3fFxMQoMTFRu3btMp5rwIABys7O1vr16yVJgYGB6tixo+bPny/pt+u3fH19NX78eE2ZMuWavdvtdtlsNuXk5MhqtZbqfrlYwKRlN23dQHmVOmeIq1sAUE5dz/t3iY405efn649//GOJmruanJwcSVLNmjUlSampqTp//ryCg4ONmhYtWqhBgwZKSUmRJKWkpKh169ZGYJKk0NBQ2e127d6926i5eB1FNUXryM/PV2pqqlNNhQoVFBwcbNRcKi8vT3a73WkCAAC3rxKFppEjR2rFihWl2khhYaEmTpyoe+65R3fffbckKT09Xe7u7qpevbpTrZeXl9LT042aiwNT0XjR2NVq7Ha7zp49q+PHj6ugoOCyNUXruNSsWbNks9mMydfXt2QbDgAAyoUSfXru3LlzWrx4sTZu3Kg2bdqoUqVKTuMvvfTSda8zMjJSu3bt0ueff16Slm652NhYRUdHG/N2u53gBADAbaxEoWnHjh1q27atJDldJyT9duPL6zVu3DitXbtWW7duVf369Y3l3t7eys/PV3Z2ttPRpoyMDHl7exs1l37KrejTdRfXXPqJu4yMDFmtVlWuXFlubm5yc3O7bE3ROi7l4eEhDw+P695WAABQPpUoNH366ael8uQOh0Pjx4/XmjVrtHnzZjVu3NhpPCAgQJUqVVJycrLCw8MlSfv379ehQ4cUFBQkSQoKCtJzzz2nzMxM1a1bV5KUlJQkq9UqPz8/o+bjjz92WndSUpKxDnd3dwUEBCg5Odm463lhYaGSk5M1bty4UtlWAABQvpUoNJWWyMhIrVixQh988IHuuOMO4/ohm82mypUry2azacSIEYqOjlbNmjVltVo1fvx4BQUFqXPnzpKkkJAQ+fn5afDgwZo9e7bS09M1depURUZGGkeCxowZo/nz52vy5MkaPny4Nm3apFWrVikxMdHoJTo6WhEREerQoYM6deqk+Ph45ebmatiwYbd+xwAAgDKnRKGpW7duVz0Nt2nTJlPrefXVVyVJXbt2dVq+ZMkSDR06VJL08ssvq0KFCgoPD1deXp5CQ0O1cOFCo9bNzU1r167V2LFjFRQUpKpVqyoiIkIzZ840aho3bqzExERFRUVp7ty5ql+/vt544w2FhoYaNf3791dWVpbi4uKUnp6utm3bav369cUuDgcAAL9PJbpPU1RUlNP8+fPnlZaWpl27dikiIkJz584ttQbLC+7TBLgO92kCUFLX8/5doiNNL7/88mWXT58+XadPny7JKgEAAMq0En/33OU8/vjj+ve//12aqwQAACgTSjU0paSkyNPTszRXCQAAUCaU6PTcxV+YK/1264Bjx47pm2++0d/+9rdSaQwAAKAsKVFostlsTvMVKlRQ8+bNNXPmTIWEhJRKYwAAAGVJiULTkiVLSrsPAACAMu2Gbm6ZmpqqvXv3SpJatWqldu3alUpTAAAAZU2JQlNmZqYGDBigzZs3G98Jl52drW7duuk///mP6tSpU5o9AgAAuFyJPj03fvx4nTp1Srt379aJEyd04sQJ7dq1S3a7XRMmTCjtHgEAAFyuREea1q9fr40bN6ply5bGMj8/Py1YsIALwQEAwG2pREeaCgsLValSpWLLK1WqpMLCwhtuCgAAoKwpUWh64IEH9NRTT+no0aPGsiNHjigqKkrdu3cvteYAAADKihKFpvnz58tut6tRo0Zq2rSpmjZtqsaNG8tut2vevHml3SMAAIDLleiaJl9fX3377bfauHGj9u3bJ0lq2bKlgoODS7U5AACAsuK6jjRt2rRJfn5+stvtslgsevDBBzV+/HiNHz9eHTt2VKtWrfTZZ5/drF4BAABc5rpCU3x8vEaNGiWr1VpszGaz6YknntBLL71Uas0BAACUFdcVmr777jv16NHjiuMhISFKTU294aYAAADKmusKTRkZGZe91UCRihUrKisr64abAgAAKGuuKzTdeeed2rVr1xXHd+zYoXr16t1wUwAAAGXNdYWmXr166W9/+5vOnTtXbOzs2bOaNm2aevfuXWrNAQAAlBXXdcuBqVOn6r333tMf/vAHjRs3Ts2bN5ck7du3TwsWLFBBQYH++te/3pRGAQAAXOm6QpOXl5e2bdumsWPHKjY2Vg6HQ5JksVgUGhqqBQsWyMvL66Y0CgAA4ErXfXPLhg0b6uOPP9bJkyf1ww8/yOFw6K677lKNGjVuRn8AAABlQonuCC5JNWrUUMeOHUuzFwAAgDKrRN89BwAA8HtDaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACS4NTVu3btVDDz0kHx8fWSwWvf/++07jQ4cOlcVicZp69OjhVHPixAkNGjRIVqtV1atX14gRI3T69Gmnmh07dui+++6Tp6enfH19NXv27GK9vPPOO2rRooU8PT3VunVrffzxx6W+vQAAoPxyaWjKzc2Vv7+/FixYcMWaHj166NixY8b09ttvO40PGjRIu3fvVlJSktauXautW7dq9OjRxrjdbldISIgaNmyo1NRUzZkzR9OnT9fixYuNmm3btumxxx7TiBEj9N///ld9+/ZV3759tWvXrtLfaAAAUC5ZHA6Hw9VNSJLFYtGaNWvUt29fY9nQoUOVnZ1d7AhUkb1798rPz09ff/21OnToIElav369evXqpV9++UU+Pj569dVX9de//lXp6elyd3eXJE2ZMkXvv/++9u3bJ0nq37+/cnNztXbtWmPdnTt3Vtu2bbVo0SJT/dvtdtlsNuXk5MhqtZZgD5gTMGnZTVs3UF6lzhni6hYAlFPX8/5d5q9p2rx5s+rWravmzZtr7Nix+vXXX42xlJQUVa9e3QhMkhQcHKwKFSroq6++Mmq6dOliBCZJCg0N1f79+3Xy5EmjJjg42Ol5Q0NDlZKScsW+8vLyZLfbnSYAAHD7KtOhqUePHlq2bJmSk5P1wgsvaMuWLerZs6cKCgokSenp6apbt67TYypWrKiaNWsqPT3dqPHy8nKqKZq/Vk3R+OXMmjVLNpvNmHx9fW9sYwEAQJlW0dUNXM2AAQOMf7du3Vpt2rRR06ZNtXnzZnXv3t2FnUmxsbGKjo425u12O8EJAIDbWJk+0nSpJk2aqHbt2vrhhx8kSd7e3srMzHSquXDhgk6cOCFvb2+jJiMjw6mmaP5aNUXjl+Ph4SGr1eo0AQCA21e5Ck2//PKLfv31V9WrV0+SFBQUpOzsbKWmpho1mzZtUmFhoQIDA42arVu36vz580ZNUlKSmjdvrho1ahg1ycnJTs+VlJSkoKCgm71JAACgnHBpaDp9+rTS0tKUlpYmSTpw4IDS0tJ06NAhnT59WpMmTdKXX36pgwcPKjk5WX369FGzZs0UGhoqSWrZsqV69OihUaNGafv27friiy80btw4DRgwQD4+PpKkgQMHyt3dXSNGjNDu3bu1cuVKzZ071+nU2lNPPaX169frxRdf1L59+zR9+nR98803Gjdu3C3fJwAAoGxyaWj65ptv1K5dO7Vr106SFB0drXbt2ikuLk5ubm7asWOHHn74Yf3hD3/QiBEjFBAQoM8++0weHh7GOpYvX64WLVqoe/fu6tWrl+69916nezDZbDZ98sknOnDggAICAvSXv/xFcXFxTvdy+uMf/6gVK1Zo8eLF8vf31+rVq/X+++/r7rvvvnU7AwAAlGll5j5N5R33aQJch/s0ASip2+o+TQAAAGUBoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJrg0NG3dulUPPfSQfHx8ZLFY9P777zuNOxwOxcXFqV69eqpcubKCg4P1/fffO9WcOHFCgwYNktVqVfXq1TVixAidPn3aqWbHjh2677775OnpKV9fX82ePbtYL++8845atGghT09PtW7dWh9//HGpby8AACi/XBqacnNz5e/vrwULFlx2fPbs2XrllVe0aNEiffXVV6patapCQ0N17tw5o2bQoEHavXu3kpKStHbtWm3dulWjR482xu12u0JCQtSwYUOlpqZqzpw5mj59uhYvXmzUbNu2TY899phGjBih//73v+rbt6/69u2rXbt23byNBwAA5YrF4XA4XN2EJFksFq1Zs0Z9+/aV9NtRJh8fH/3lL3/R008/LUnKycmRl5eXEhISNGDAAO3du1d+fn76+uuv1aFDB0nS+vXr1atXL/3yyy/y8fHRq6++qr/+9a9KT0+Xu7u7JGnKlCl6//33tW/fPklS//79lZubq7Vr1xr9dO7cWW3bttWiRYtM9W+322Wz2ZSTkyOr1Vpau6WYgEnLbtq6gfIqdc4QV7cAoJy6nvfvMntN04EDB5Senq7g4GBjmc1mU2BgoFJSUiRJKSkpql69uhGYJCk4OFgVKlTQV199ZdR06dLFCEySFBoaqv379+vkyZNGzcXPU1RT9DyXk5eXJ7vd7jQBAIDbV5kNTenp6ZIkLy8vp+VeXl7GWHp6uurWres0XrFiRdWsWdOp5nLruPg5rlRTNH45s2bNks1mMyZfX9/r3UQAAFCOlNnQVNbFxsYqJyfHmA4fPuzqlgAAwE1UZkOTt7e3JCkjI8NpeUZGhjHm7e2tzMxMp/ELFy7oxIkTTjWXW8fFz3GlmqLxy/Hw8JDVanWaAADA7avMhqbGjRvL29tbycnJxjK73a6vvvpKQUFBkqSgoCBlZ2crNTXVqNm0aZMKCwsVGBho1GzdulXnz583apKSktS8eXPVqFHDqLn4eYpqip4HAADApaHp9OnTSktLU1pamqTfLv5OS0vToUOHZLFYNHHiRD377LP68MMPtXPnTg0ZMkQ+Pj7GJ+xatmypHj16aNSoUdq+fbu++OILjRs3TgMGDJCPj48kaeDAgXJ3d9eIESO0e/durVy5UnPnzlV0dLTRx1NPPaX169frxRdf1L59+zR9+nR98803Gjdu3K3eJQAAoIyq6Mon/+abb9StWzdjvijIREREKCEhQZMnT1Zubq5Gjx6t7Oxs3XvvvVq/fr08PT2Nxyxfvlzjxo1T9+7dVaFCBYWHh+uVV14xxm02mz755BNFRkYqICBAtWvXVlxcnNO9nP74xz9qxYoVmjp1qp555hndddddev/993X33Xffgr0AAADKgzJzn6byjvs0Aa7DfZoAlNRtcZ8mAACAsoTQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATynRomj59uiwWi9PUokULY/zcuXOKjIxUrVq1VK1aNYWHhysjI8NpHYcOHVJYWJiqVKmiunXratKkSbpw4YJTzebNm9W+fXt5eHioWbNmSkhIuBWbBwAAypEyHZokqVWrVjp27Jgxff7558ZYVFSUPvroI73zzjvasmWLjh49qkceecQYLygoUFhYmPLz87Vt2zYtXbpUCQkJiouLM2oOHDigsLAwdevWTWlpaZo4caJGjhypDRs23NLtBAAAZVtFVzdwLRUrVpS3t3ex5Tk5OfrXv/6lFStW6IEHHpAkLVmyRC1bttSXX36pzp0765NPPtGePXu0ceNGeXl5qW3btvr73/+umJgYTZ8+Xe7u7lq0aJEaN26sF198UZLUsmVLff7553r55ZcVGhp6S7cVAACUXWX+SNP3338vHx8fNWnSRIMGDdKhQ4ckSampqTp//ryCg4ON2hYtWqhBgwZKSUmRJKWkpKh169by8vIyakJDQ2W327V7926j5uJ1FNUUrQMAAEAq40eaAgMDlZCQoObNm+vYsWOaMWOG7rvvPu3atUvp6elyd3dX9erVnR7j5eWl9PR0SVJ6erpTYCoaLxq7Wo3dbtfZs2dVuXLly/aWl5envLw8Y95ut9/QtgIAgLKtTIemnj17Gv9u06aNAgMD1bBhQ61ateqKYeZWmTVrlmbMmOHSHgAAwK1T5k/PXax69er6wx/+oB9++EHe3t7Kz89Xdna2U01GRoZxDZS3t3exT9MVzV+rxmq1XjWYxcbGKicnx5gOHz58o5sHAADKsHIVmk6fPq0ff/xR9erVU0BAgCpVqqTk5GRjfP/+/Tp06JCCgoIkSUFBQdq5c6cyMzONmqSkJFmtVvn5+Rk1F6+jqKZoHVfi4eEhq9XqNAEAgNtXmT499/TTT+uhhx5Sw4YNdfToUU2bNk1ubm567LHHZLPZNGLECEVHR6tmzZqyWq0aP368goKC1LlzZ0lSSEiI/Pz8NHjwYM2ePVvp6emaOnWqIiMj5eHhIUkaM2aM5s+fr8mTJ2v48OHatGmTVq1apcTERFduOoDfoYBJy1zdAlDmpM4Z4uoWDGU6NP3yyy967LHH9Ouvv6pOnTq699579eWXX6pOnTqSpJdfflkVKlRQeHi48vLyFBoaqoULFxqPd3Nz09q1azV27FgFBQWpatWqioiI0MyZM42axo0bKzExUVFRUZo7d67q16+vN954g9sNAAAAJxaHw+FwdRO3A7vdLpvNppycnJt6qo6/RIHiytJfojeC1zdQ3M1+fV/P+3e5uqYJAADAVQhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0HSJBQsWqFGjRvL09FRgYKC2b9/u6pYAAEAZQGi6yMqVKxUdHa1p06bp22+/lb+/v0JDQ5WZmenq1gAAgIsRmi7y0ksvadSoURo2bJj8/Py0aNEiValSRf/+979d3RoAAHAxQtP/yc/PV2pqqoKDg41lFSpUUHBwsFJSUlzYGQAAKAsqurqBsuL48eMqKCiQl5eX03IvLy/t27evWH1eXp7y8vKM+ZycHEmS3W6/qX0W5J29qesHyqOb/bq7VXh9A8Xd7Nd30fodDsc1awlNJTRr1izNmDGj2HJfX18XdAP8vtnmjXF1CwBuklv1+j516pRsNttVawhN/6d27dpyc3NTRkaG0/KMjAx5e3sXq4+NjVV0dLQxX1hYqBMnTqhWrVqyWCw3vV+4lt1ul6+vrw4fPiyr1erqdgCUIl7fvy8Oh0OnTp2Sj4/PNWsJTf/H3d1dAQEBSk5OVt++fSX9FoSSk5M1bty4YvUeHh7y8PBwWla9evVb0CnKEqvVyv9UgdsUr+/fj2sdYSpCaLpIdHS0IiIi1KFDB3Xq1Enx8fHKzc3VsGHDXN0aAABwMULTRfr376+srCzFxcUpPT1dbdu21fr164tdHA4AAH5/CE2XGDdu3GVPxwEX8/Dw0LRp04qdogVQ/vH6xpVYHGY+YwcAAPA7x80tAQAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJuAqunbtqgkTJmjy5MmqWbOmvL29NX36dGP80KFD6tOnj6pVqyar1ao///nPxb6/EEDZsGzZMtWqVUt5eXlOy/v27avBgwdLkj744AO1b99enp6eatKkiWbMmKELFy5I+u07yqZPn64GDRrIw8NDPj4+mjBhwi3fDrgOoQm4hqVLl6pq1ar66quvNHv2bM2cOVNJSUkqLCxUnz59dOLECW3ZskVJSUn66aef1L9/f1e3DOAyHn30URUUFOjDDz80lmVmZioxMVHDhw/XZ599piFDhuipp57Snj179NprrykhIUHPPfecJOndd9/Vyy+/rNdee03ff/+93n//fbVu3dpVmwMX4OaWwFV07dpVBQUF+uyzz4xlnTp10gMPPKDu3burZ8+eOnDggHx9fSVJe/bsUatWrbR9+3Z17NjRVW0DuIInn3xSBw8e1McffyxJeumll7RgwQL98MMPevDBB9W9e3fFxsYa9W+99ZYmT56so0eP6qWXXtJrr72mXbt2qVKlSq7aBLgQR5qAa2jTpo3TfL169ZSZmam9e/fK19fXCEyS5Ofnp+rVq2vv3r23uk0AJowaNUqffPKJjhw5IklKSEjQ0KFDZbFY9N1332nmzJmqVq2aMY0aNUrHjh3TmTNn9Oijj+rs2bNq0qSJRo0apTVr1hin7vD7wHfPAddw6V+UFotFhYWFLuoGwI1o166d/P39tWzZMoWEhGj37t1KTEyUJJ0+fVozZszQI488Uuxxnp6e8vX11f79+7Vx40YlJSXpySef1Jw5c7RlyxaOPP1OEJqAEmrZsqUOHz6sw4cPO52ey87Olp+fn4u7A3AlI0eOVHx8vI4cOaLg4GDj9du+fXvt379fzZo1u+JjK1eurIceekgPPfSQIiMj1aJFC+3cuVPt27e/Ve3DhQhNQAkFBwerdevWGjRokOLj43XhwgU9+eSTuv/++9WhQwdXtwfgCgYOHKinn35ar7/+upYtW2Ysj4uLU+/evdWgQQP169dPFSpU0Hfffaddu3bp2WefVUJCggoKChQYGKgqVarorbfeUuXKldWwYUMXbg1uJa5pAkrIYrHogw8+UI0aNdSlSxcFBwerSZMmWrlypatbA3AVNptN4eHhqlatmvr27WssDw0N1dq1a/XJJ5+oY8eO6ty5s15++WUjFFWvXl2vv/667rnnHrVp00YbN27URx99pFq1arloS3Cr8ek5AMDvTvfu3dWqVSu98sorrm4F5QihCQDwu3Hy5Elt3rxZ/fr10549e9S8eXNXt4RyhGuaAAC/G+3atdPJkyf1wgsvEJhw3TjSBAAAYAIXggMAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoA4DKWLVumWrVqKS8vz2l53759NXjwYBd1BcCVCE0AcBmPPvqoCgoK9OGHHxrLMjMzlZiYqOHDh7uwMwCuQmgCgMuoXLmyBg4cqCVLlhjL3nrrLTVo0EBdu3Z1XWMAXIbQBABXMGrUKH3yySc6cuSIJCkhIUFDhw6VxWJxcWcAXIHvngOAqwgICFC/fv0UEhKiTp066eDBg/L19XV1WwBcoKKrGwCAsmzkyJGKj4/XkSNHFBwcTGACfsc40gQAV5GTkyMfHx9duHBBy5YtU//+/V3dEgAX4ZomALgKm82m8PBwVatWTX379nV1OwBciNAEANdw5MgRDRo0SB4eHq5uBYALcXoOAK7g5MmT2rx5s/r166c9e/aoefPmrm4JgAtxITgAXEG7du108uRJvfDCCwQmABxpAgAAMINrmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABM+H9d3OcfPQ4QYAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(data=df, x='y')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of \"yes\" and \"no\" in column y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this segment, the notebook transitions into the preparation phase for machine learning modeling by splitting the dataset into training and test sets. This step is fundamental for evaluating the performance of the predictive models. The code utilizes the **`train_test_split`** function from **`sklearn.model_selection`**, a module of the scikit-learn library designed for splitting datasets into random train and test subsets.\n",
    "\n",
    "The dataset is divided into features (**`X`**) and the target variable (**`y`**), with **`X`** containing all columns except for the target column **`y`**, which is achieved using the **`df.drop`** method. The target variable **`y`** is isolated in its own Series.\n",
    "\n",
    "The **`train_test_split`** function is then called with **`X`** and **`y`** as inputs, along with two key parameters: **`test_size`** set to 0.3, indicating that 30% of the data will be used for the test set, and **`random_state`** set to 42, ensuring reproducibility of the results by controlling the random number generator used for the split.\n",
    "\n",
    "This function returns four subsets: **`X_train`** and **`y_train`** for training the model, and **`X_test`** and **`y_test`** for evaluating the model's performance.\n",
    "\n",
    "#### Evaluation of Dataset Splitting\n",
    "\n",
    "Splitting the dataset into training and test sets is a crucial practice in machine learning to assess the performance of algorithms on unseen data. It helps in understanding how well the model can generalize from the training data to new data.\n",
    "\n",
    "-   **Advantages**:\n",
    "\n",
    "    -   Facilitates the evaluation of the model's generalization ability, a critical aspect of machine learning models.\n",
    "\n",
    "    -   Prevents overfitting by ensuring that the model's performance is tested on unseen data.\n",
    "\n",
    "-   **Considerations**:\n",
    "\n",
    "    -   The choice of **`test_size=0.3`** is a common practice, offering a balance between having enough data for training and enough data for testing. However, the optimal ratio may vary depending on the dataset size and the specific problem.\n",
    "\n",
    "    -   The use of **`random_state=42`** ensures that the results are reproducible, which is important for experimental consistency. However, it's also valuable to test the model's robustness to different splits of the data, especially in the fine-tuning and model selection phases.\n",
    "\n",
    "This dataset splitting step is implemented correctly, using best practices for preparing the data for subsequent modeling. By creating distinct training and test sets, it lays the groundwork for training machine learning models and evaluating their ability to predict outcomes on new, unseen data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the notebook is dedicated to training a machine learning model using the Naive Bayes algorithm, specifically the Gaussian Naive Bayes variant, making predictions on the test set, and evaluating the model's performance using accuracy as the metric. It also includes preprocessing steps for encoding categorical features into numerical format, which is a requirement for most machine learning algorithms, including Naive Bayes.\n",
    "\n",
    "Firstly, the **`LabelEncoder`** from **`sklearn.preprocessing`** is instantiated. It is used to convert each unique string value into a numeric format, making the data suitable for the algorithm. This encoding is applied to all categorical columns (**`dtype == 'object'`**) in both the training and test feature sets (**`X_train`** and **`X_test`**).\n",
    "\n",
    "The **`GaussianNB`** class from **`sklearn.naive_bayes`** is then instantiated and fitted to the training data (**`X_train`**, **`y_train`**), resulting in a trained model. The **`.predict()`** method of this model is used to generate predictions (**`y_pred`**) for the test set (**`X_test`**).\n",
    "\n",
    "Finally, the accuracy of the model is computed by comparing the predicted labels (**`y_pred`**) with the true labels (**`y_test`**) of the test set, using the **`accuracy_score`** function from **`sklearn.metrics`**.\n",
    "\n",
    "#### Evaluation of Model Training, Prediction, and Evaluation\n",
    "\n",
    "-   **Model Choice**: Gaussian Naive Bayes is a good choice for classification tasks and can perform well even with a small amount of data. It's particularly suited for datasets where features are normally distributed.\n",
    "\n",
    "-   **Label Encoding**: The approach of encoding categorical variables is necessary for Naive Bayes, as it only works with numerical data. However, this method assumes an ordinal relationship between categories, which might not always be the case. For nominal data, one-hot encoding could be considered, though it increases the feature space dimensionality.\n",
    "\n",
    "-   **Accuracy Metric**: Accuracy is a straightforward metric for evaluating classification models, representing the fraction of predictions the model got right. While useful, accuracy alone might not provide a complete picture of the model's performance, especially in imbalanced datasets where the majority class dominates the prediction. In such cases, other metrics like precision, recall, F1-score, and confusion matrices provide more insight.\n",
    "\n",
    "-   **Model Training and Prediction**: The use of **`fit`** and **`predict`** methods follows the standard workflow in scikit-learn for model training and prediction, showcasing the library's ease of use and consistency across different types of models.\n",
    "\n",
    "-   **Considerations**:\n",
    "\n",
    "    -   When applying **`LabelEncoder`**, it's essential to handle unseen labels that might appear in the test set or future data, which could cause the encoder to throw an error. Strategies include using the **`handle_unknown`** parameter with encoders that support it, such as **`sklearn.preprocessing.OrdinalEncoder`**.\n",
    "\n",
    "    -   Given the class imbalance observed earlier in the dataset, evaluating the model with additional metrics would be beneficial to understand its performance comprehensively.\n",
    "\n",
    "This section efficiently encapsulates the end-to-end process of training a Naive Bayes model on preprocessed data, making predictions, and evaluating the model's accuracy. It's well-structured and follows best practices for a basic machine learning workflow, with room for incorporating more nuanced evaluation metrics and encoding strategies for a more thorough analysis.\n",
    "\n",
    "The output indicates that the Gaussian Naive Bayes model achieved an accuracy of approximately 85.01% on the test set. This metric reflects the proportion of correct predictions made by the model out of all predictions.\n",
    "\n",
    "#### Interpretation of Accuracy\n",
    "\n",
    "-   **General Performance**: An accuracy of 85.01% is relatively high, suggesting that the model is capable of correctly identifying whether a client will subscribe to a term deposit in the majority of cases. This level of accuracy can be considered good in many contexts, especially if the baseline accuracy (e.g., always predicting the majority class) is significantly lower.\n",
    "\n",
    "-   **Contextual Performance**: The effectiveness of this accuracy rate should be evaluated in the context of the problem domain and the dataset's balance. Given the earlier noted class imbalance (with a much higher number of **`no`** responses compared to **`yes`**), it's important to assess whether this accuracy is achieved by genuinely learning from the features or primarily by predicting the majority class.\n",
    "\n",
    "#### Considerations for Further Evaluation\n",
    "\n",
    "-   **Class Imbalance**: Given the imbalance in the dataset, accuracy might not be the most informative metric. The model might achieve high accuracy by predominantly predicting the majority class. Metrics such as precision, recall, F1-score, and ROC AUC are more robust in such scenarios, as they can provide insights into how well the model performs across both classes.\n",
    "\n",
    "-   **Model Comparison**: Comparing this model's performance with other models (e.g., Decision Trees, Logistic Regression) could offer insights into the effectiveness of Gaussian Naive Bayes for this specific dataset and problem.\n",
    "\n",
    "-   **Feature Importance**: Investigating which features most significantly influence the model's predictions can provide insights into the dataset and suggest areas for feature engineering or selection.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "The reported accuracy of 85.01% for the Gaussian Naive Bayes model is promising but requires a nuanced interpretation considering the dataset's characteristics, especially the class imbalance. Further evaluation with additional metrics and comparison with other models could provide a more comprehensive understanding of the model's performance and potential areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8501254349761269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == 'object':\n",
    "        X_train[col] = le.fit_transform(X_train[col])\n",
    "        X_test[col] = le.transform(X_test[col])\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment of the notebook extends the model evaluation process by applying cross-validation to the Gaussian Naive Bayes model. Cross-validation is a robust technique for assessing the model's generalizability by dividing the dataset into a specified number (**`cv=5`**) of distinct subsets, or folds. The model is then trained and evaluated five times, each time using a different fold as the test set and the remaining folds combined as the training set.\n",
    "\n",
    "The code starts by re-encoding all categorical variables in the entire dataset (**`X`**) using **`LabelEncoder`**, ensuring that all features are in a numeric format suitable for the Gaussian Naive Bayes model. It's important to note that, unlike the previous model training where only the training set was transformed, this encoding is applied across the entire dataset before the cross-validation process.\n",
    "\n",
    "**`cross_val_score`** from **`sklearn.model_selection`** is used to perform the cross-validation, with the model (**`gnb`**), features (**`X`**), target variable (**`y`**), and number of folds (**`cv=5`**) as inputs. This function returns the scores from each fold of cross-validation, which are then printed along with the average score across all folds.\n",
    "\n",
    "#### Evaluation of Cross-validation Results\n",
    "\n",
    "-   **Cross-validation Scores**: The individual cross-validation scores show significant variability, ranging from 0.8917 to 0.1202. This variation suggests differences in the model's performance across different subsets of the data, indicating potential issues with the model's generalizability or with certain segments of the data being more challenging to predict.\n",
    "\n",
    "-   **Average Cross-validation Score**: The average score of approximately 72.65% is lower than the accuracy previously obtained on a single test split (85.01%). This discrepancy highlights the importance of cross-validation in providing a more nuanced view of the model's performance, as it assesses how well the model generalizes to unseen data in a more robust manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.89172129 0.90531682 0.92522457 0.79057909 0.12018939]\n",
      "Average cross-validation score:  0.7266062337577973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "scores = cross_val_score(gnb, X, y, cv=5)\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Average cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8501254349761269\n",
      "F1 score:  0.47889701744513224\n",
      "Recall:  0.6126709863210943\n",
      "Precision:  0.3930715935334873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "f1 = f1_score(y_test, y_pred, pos_label='yes')\n",
    "recall = recall_score(y_test, y_pred, pos_label='yes')\n",
    "precision = precision_score(y_test, y_pred, pos_label='yes')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "#### Code Overview\n",
    "\n",
    "The code snippet initiates the process by importing the **`pandas`** library, essential for data manipulation and analysis in Python. It then proceeds to load a dataset named 'bank-full.csv' into a pandas DataFrame. This dataset appears to be related to a bank's marketing campaign, containing various attributes of clients and campaign details.\n",
    "\n",
    "The dataset is loaded using **`pd.read_csv`**, with a specified separator **`sep=';'`**, indicating that the data values are semicolon-separated. Following the loading, the first few rows of the DataFrame are displayed using **`df.head()`**, providing a quick overview of the data's structure and the types of variables included.\n",
    "\n",
    "#### Dataset Overview\n",
    "\n",
    "The displayed output reveals several columns, totaling 21, which include both client-specific information (e.g., **`age`**, **`job`**, **`marital`**, **`education`**, **`default`**, **`housing`**, **`loan`**) and details about the marketing campaign interactions (**`contact`**, **`month`**, **`day_of_week`**, **`campaign`**, **`pdays`**, **`previous`**, **`poutcome`**). Economic factors are also recorded (**`emp.var.rate`**, **`cons.price.idx`**, **`cons.conf.idx`**, **`euribor3m`**, **`nr.employed`**), alongside the target variable **`y`**, indicating the campaign outcome (whether the client subscribed to a term deposit).\n",
    "\n",
    "#### Initial Observations\n",
    "\n",
    "-   **Data Types**: The dataset contains a mix of numerical and categorical variables, necessitating different preprocessing strategies for each type.\n",
    "\n",
    "-   **Target Variable (`y`)**: The binary nature of the target variable (**`yes`**, **`no`**) suggests this is a classification problem.\n",
    "\n",
    "-   **Missing Values and Data Quality**: Initial inspection doesn't reveal missing values or data quality issues in the first few rows, but a thorough assessment will be necessary.\n",
    "\n",
    "-   **Potential for Feature Engineering**: Some variables, like **`job`**, **`education`**, and **`contact`**, might benefit from encoding or feature engineering to better capture their impact on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('bank-full.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this phase, the focus shifts to preprocessing the numerical variables within the dataset to ensure they are on a standardized scale. The code snippet utilizes the **`StandardScaler`** from scikit-learn's preprocessing module, which standardizes features by removing the mean and scaling to unit variance (z-score normalization).\n",
    "\n",
    "The process involves creating an instance of **`StandardScaler`** followed by identifying numerical columns in the dataset. These columns are selected based on their data types, specifically **`int64`** and **`float64`**, indicating numerical data. The identified columns are then standardized using the **`fit_transform`** method of the scaler, which adjusts the data such that its distribution will have a mean value 0 and standard deviation of 1. This transformation is applied directly to the DataFrame, updating the numerical columns with their standardized values.\n",
    "\n",
    "The transformed DataFrame's first few rows are displayed, showing the standardized numerical values alongside the original categorical values.\n",
    "\n",
    "#### Evaluation of Data Standardization\n",
    "\n",
    "-   **Normalization Benefits**: Standardization of numerical data is particularly beneficial when using machine learning algorithms sensitive to the magnitude of variables, such as support vector machines and k-nearest neighbors. It ensures that each feature contributes approximately proportionately to the final prediction.\n",
    "\n",
    "-   **Handling Categorical Data**: It's noted that only numerical columns are standardized. Categorical variables remain untouched in this step, which is appropriate since **`StandardScaler`** is designed for continuous data. These categorical features will require separate preprocessing (e.g., encoding) to be usable by machine learning models.\n",
    "\n",
    "#### Key Insights from Output\n",
    "\n",
    "The output confirms the successful standardization of numerical columns in the dataset. Each numerical feature now has values expressed in terms of z-scores, which aligns with the goal of standardizing data. Categorical features are displayed as is, highlighting the mixed data types present in the dataset and underscoring the necessity for comprehensive preprocessing that accommodates both numerical and categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.628993</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.290186</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002309</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   job             marital    education             default   \\\n",
       "0  1.533034  housemaid       married    basic.4y              no         \n",
       "1  1.628993  services        married    high.school           unknown    \n",
       "2 -0.290186  services        married    high.school           no         \n",
       "3 -0.002309  admin.          married    basic.6y              no         \n",
       "4  1.533034  services        married    high.school           no         \n",
       "\n",
       "   housing   loan      contact     month   day_of_week   ...  campaign   \\\n",
       "0  no        no        telephone   may     mon           ...  -0.565922   \n",
       "1  no        no        telephone   may     mon           ...  -0.565922   \n",
       "2  yes       no        telephone   may     mon           ...  -0.565922   \n",
       "3  no        no        telephone   may     mon           ...  -0.565922   \n",
       "4  no        yes       telephone   may     mon           ...  -0.565922   \n",
       "\n",
       "     pdays   previous   poutcome     emp.var.rate   cons.price.idx   \\\n",
       "0  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "1  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "2  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "3  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "4  0.195414  -0.349494  nonexistent       0.648092         0.722722   \n",
       "\n",
       "   cons.conf.idx   euribor3m   nr.employed    y  \n",
       "0        0.886447     0.71246       0.33168  no  \n",
       "1        0.886447     0.71246       0.33168  no  \n",
       "2        0.886447     0.71246       0.33168  no  \n",
       "3        0.886447     0.71246       0.33168  no  \n",
       "4        0.886447     0.71246       0.33168  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code segment outlines a comprehensive approach to preparing the dataset for a machine learning task, specifically using a Decision Tree Classifier for prediction. It covers categorical data encoding, feature and target variable separation, data splitting into training and test sets, model training, prediction, and performance evaluation.\n",
    "\n",
    "-   **Categorical Data Encoding**: The **`LabelEncoder`** from scikit-learn is applied to all columns in the DataFrame, transforming categorical features into numerical format. This step is crucial as decision trees and most other machine learning algorithms require numerical input.\n",
    "\n",
    "-   **Feature and Target Definition**: The dataset is divided into features (**`X`**) and the target variable (**`y`**), where **`X`** contains all columns except the target variable **`y`**, indicating the outcome of interest.\n",
    "\n",
    "-   **Data Splitting**: The **`train_test_split`** function is used to separate the data into training and test sets, with 20% of the data reserved for testing. This split ensures that the model can be evaluated on unseen data.\n",
    "\n",
    "-   **Model Training**: A **`DecisionTreeClassifier`** instance is created and fitted to the training data. Decision trees are versatile models that can handle both classification and regression tasks but require careful tuning to avoid overfitting.\n",
    "\n",
    "-   **Prediction and Evaluation**: Predictions are made on the test set, and various performance metrics are computed, including accuracy, F1 score, recall, and precision. These metrics provide a holistic view of the model's performance, highlighting its strengths and areas for improvement.\n",
    "\n",
    "#### Performance Metrics Evaluation\n",
    "\n",
    "-   **Accuracy (88.77%)**: Indicates a high overall rate of correct predictions. This metric suggests that the decision tree model performs well in classifying the outcomes.\n",
    "\n",
    "-   **F1 Score (50.98%)**: Significantly lower than accuracy, reflecting a balance between precision and recall but highlighting potential room for improvement, especially in handling the positive class effectively.\n",
    "\n",
    "-   **Recall (51.44%)**: Shows that the model identifies a little over half of the actual positive cases correctly. This metric is crucial in scenarios where missing positive cases is costly.\n",
    "\n",
    "-   **Precision (50.53%)**: Indicates that slightly more than half of the positive predictions made by the model are correct. In contexts where false positives have implications, there's a need for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8897790725904345\n",
      "F1 score:  0.5180467091295117\n",
      "Recall:  0.5219251336898396\n",
      "Precision:  0.5142255005268704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df = df.apply(le.fit_transform)\n",
    "\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "When comparing the performance of the Naive Bayes and Decision Tree classifiers on the dataset, it's important to consider the context of the task and the nature of the data to understand the implications of these metrics fully. Here's a detailed comparison based on the provided results:\n",
    "\n",
    "### **Accuracy**\n",
    "\n",
    "-   **Naive Bayes**: 85.01%\n",
    "\n",
    "-   **Decision Trees**: 88.77%\n",
    "\n",
    "**Analysis**: Both models show strong overall performance, with Decision Trees slightly outperforming Naive Bayes in terms of accuracy. This suggests that Decision Trees may be better at generalizing across the dataset, capturing the underlying patterns with slightly more effectiveness.\n",
    "\n",
    "### **F1 Score**\n",
    "\n",
    "-   **Naive Bayes**: 47.89%\n",
    "\n",
    "-   **Decision Trees**: 50.98%\n",
    "\n",
    "**Analysis**: The F1 score, which balances precision and recall, is notably higher for the Decision Trees model. This indicates that Decision Trees offer a better balance between identifying relevant instances and minimizing false positives, particularly beneficial in imbalanced datasets or when both false positives and false negatives are costly.\n",
    "\n",
    "### **Recall**\n",
    "\n",
    "-   **Naive Bayes**: 61.27%\n",
    "\n",
    "-   **Decision Trees**: 51.44%\n",
    "\n",
    "**Analysis**: Naive Bayes demonstrates a higher recall than Decision Trees, suggesting it is more effective at identifying all positive instances, potentially at the expense of incurring more false positives. In applications where missing positive instances has significant consequences (e.g., fraud detection), Naive Bayes might be preferred.\n",
    "\n",
    "### **Precision**\n",
    "\n",
    "-   **Naive Bayes**: 39.31%\n",
    "\n",
    "-   **Decision Trees**: 50.53%\n",
    "\n",
    "**Analysis**: Decision Trees show a higher precision compared to Naive Bayes, indicating that when they predict an instance to be positive, it is more likely to be correct. This model might be preferable in scenarios where false positives have a higher cost.\n",
    "\n",
    "### **Overall Comparison**\n",
    "\n",
    "-   **Decision Trees** seem to offer a more balanced performance across the board, with particularly stronger accuracy and precision. This suggests they might be more suitable for scenarios where the cost of false positives is significant, or a balanced approach to classification is required.\n",
    "\n",
    "-   **Naive Bayes**, with its higher recall, might be preferred in situations where identifying as many positive instances as possible is crucial, even if it means accepting more false positives. Its simpler assumptions and faster training times could also make it advantageous for very large datasets or as a baseline model.\n",
    "\n",
    "### **Final Considerations**\n",
    "\n",
    "The choice between Naive Bayes and Decision Trees should consider the specific requirements of the classification task, including the relative costs of false positives and false negatives, the nature of the dataset, and the computational resources available. Further tuning and experimentation, possibly incorporating additional evaluation metrics and validation techniques, could also help refine these models for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook begins by importing the **`pandas`** library and other needed libraries, a powerful tool for data manipulation and analysis in Python. The code then specifies the file path for the dataset 'bank-full.csv', which is presumed to contain data related to a bank's marketing campaign.\n",
    "\n",
    "Using the **`pd.read_csv`** function, the dataset is loaded into a pandas DataFrame. This function is highly versatile and capable of handling various delimiters; here, it's instructed to use a semicolon (**`sep=';'`**) based on the dataset's structure. Once loaded, the first five rows of the DataFrame are displayed using the **`.head()`** method, providing a quick glance at the dataset's features and initial rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\natal\\\\OneDrive\\\\Plocha\\\\vš\\\\6.semestr\\\\HAN\\\\06data mining\\\\bank-full.csv\", delimiter=';')\n",
    "\n",
    "# Display the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display info about the dataset\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Target Variable\n",
    "\n",
    "In this section, the target variable 'y' is analyzed to understand the distribution of its categories ('yes' and 'no').\n",
    "\n",
    "#### Explanation:\n",
    "\n",
    "- **Counting Categories:** The `value_counts()` function is used to count the occurrences of each category in the target variable 'y'. This provides insights into the balance or imbalance of the classes within the dataset.\n",
    "\n",
    "- **Proportions:** Additionally, the proportion of each category is calculated by setting `normalize=True` in the `value_counts()` function. This allows us to see the relative frequency of each category compared to the total number of observations.\n",
    "\n",
    "- **Results:** The counts and proportions are displayed to provide a summary of the distribution of the target variable. This information is crucial for understanding the baseline performance of the model and identifying potential issues such as class imbalance.\n",
    "\n",
    "By analyzing the target variable, we gain valuable insights that inform the modeling process and help in selecting appropriate evaluation metrics and strategies for handling class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "no     0.887346\n",
       "yes    0.112654\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cntAdd = data[\"y\"].value_counts()\n",
    "propAdd = data[\"y\"].value_counts(normalize=True)\n",
    "cntAdd\n",
    "propAdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing - Standardization\n",
    "\n",
    "Data preprocessing is a crucial step in machine learning workflows that involves transforming raw data into a format suitable for modeling. One common preprocessing technique is standardization, which aims to rescale the features so that they have the properties of a standard normal distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "The purpose of the **Standardization** step is to ensure that all numerical features have a similar scale, preventing features with larger magnitudes from dominating the learning process during model training. This is particularly important for distance-based algorithms like K-Nearest Neighbors (KNN), where differences in feature scales can significantly impact the results.\n",
    "\n",
    "#### Process\n",
    "\n",
    "1. **Instantiate StandardScaler**: First, an instance of the **`StandardScaler`** class from **`sklearn.preprocessing`** is created. This scaler will be used to perform the standardization.\n",
    "\n",
    "2. **Select Numerical Columns**: The numerical columns in the dataset are identified using **`select_dtypes`** method with the parameter **`include=['int64', 'float64']`**. These columns are the ones that require standardization.\n",
    "\n",
    "3. **Standardize Numerical Features**: The selected numerical columns are standardized using the **`fit_transform`** method of the **`StandardScaler`** object. This method computes the mean and standard deviation of each feature in the training set and then transforms the data based on these statistics.\n",
    "\n",
    "4. **Update Dataset**: The original numerical columns in the dataset are replaced with their standardized versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.628993</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.290186</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002309</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age        job  marital    education  default housing loan    contact  \\\n",
       "0  1.533034  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1  1.628993   services  married  high.school  unknown      no   no  telephone   \n",
       "2 -0.290186   services  married  high.school       no     yes   no  telephone   \n",
       "3 -0.002309     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4  1.533034   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign     pdays  previous     poutcome  \\\n",
       "0   may         mon  ... -0.565922  0.195414 -0.349494  nonexistent   \n",
       "1   may         mon  ... -0.565922  0.195414 -0.349494  nonexistent   \n",
       "2   may         mon  ... -0.565922  0.195414 -0.349494  nonexistent   \n",
       "3   may         mon  ... -0.565922  0.195414 -0.349494  nonexistent   \n",
       "4   may         mon  ... -0.565922  0.195414 -0.349494  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0     0.648092        0.722722       0.886447    0.71246      0.33168  no  \n",
       "1     0.648092        0.722722       0.886447    0.71246      0.33168  no  \n",
       "2     0.648092        0.722722       0.886447    0.71246      0.33168  no  \n",
       "3     0.648092        0.722722       0.886447    0.71246      0.33168  no  \n",
       "4     0.648092        0.722722       0.886447    0.71246      0.33168  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing: Encode categorical variables\n",
    "\n",
    "In this section, the categorical variables are encoded to numerical format to prepare the data for machine learning algorithms. \n",
    "\n",
    "#### Explanation:\n",
    "\n",
    "The categorical variables in the DataFrame are encoded using one-hot encoding technique, which converts categorical variables into a binary matrix representation. This ensures that each category within a categorical variable is represented as a separate binary feature column, which is essential for many machine learning algorithms to interpret categorical data correctly.\n",
    "\n",
    "- **`X = df.drop(['y'], axis=1)`:** The target variable 'y' is dropped from the DataFrame to create the feature matrix 'X', which contains all the independent variables.\n",
    "\n",
    "- **`X = pd.get_dummies(df)`:** The `get_dummies()` function from pandas is used to perform one-hot encoding on the entire DataFrame. It converts categorical variables into dummy/indicator variables.\n",
    "\n",
    "- **`X = X.values`:** The resulting DataFrame is converted into a numpy array for compatibility with machine learning models.\n",
    "\n",
    "- **`Y = df.iloc[:,-1].values`:** The target variable 'y' is extracted from the DataFrame and stored in the array 'Y'. This array contains the labels or outcomes that the model will predict.\n",
    "\n",
    "This preprocessing step ensures that all the data is in a suitable format for training machine learning models, as most algorithms require numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['y'], axis = 1 )\n",
    "X = pd.get_dummies(data)\n",
    "X = X.values\n",
    "\n",
    "Y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split Using train_test_split Function\n",
    "\n",
    "In machine learning, it's essential to evaluate the performance of a model on data that it hasn't seen during training. The **train_test_split** function from the **sklearn.model_selection** module is a widely used utility for splitting a dataset into training and testing sets.\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "The purpose of splitting the data into training and testing sets is to:\n",
    "\n",
    "- **Train the Model**: The training set is used to fit the model's parameters, allowing it to learn patterns and relationships in the data.\n",
    "\n",
    "- **Test the Model**: The testing set is used to evaluate the model's performance on unseen data. This helps assess how well the model generalizes to new observations.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- **X**: The feature matrix containing the independent variables or predictors.\n",
    "  \n",
    "- **Y**: The target variable or dependent variable that we want to predict.\n",
    "\n",
    "- **test_size**: The proportion of the dataset to include in the testing set. It's typically specified as a float between 0 and 1, representing the fraction of the dataset to allocate to the testing set.\n",
    "\n",
    "- **random_state**: Controls the randomness of the data splitting process. Setting a random state ensures reproducibility, as the same random split will be generated each time the function is called with the same seed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size =.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training: k-Nearest Neighbors (KNN)\n",
    "\n",
    "In this section, we train a k-Nearest Neighbors (KNN) classifier to predict the target variable based on the input features.\n",
    "\n",
    "#### Explanation:\n",
    "\n",
    "The k-Nearest Neighbors algorithm is a versatile and intuitive method used for classification and regression tasks. It makes predictions by identifying the 'k' nearest data points to a given query point in the feature space and assigning the majority class (for classification) or computing the average (for regression) of the 'k' nearest neighbors.\n",
    "\n",
    "- **Classifier Initialization:** We initialize a KNeighborsClassifier object named 'KNN' with various parameters to configure the behavior of the KNN algorithm. These parameters include:\n",
    "  - `n_neighbors`: The number of neighbors to consider when making predictions.\n",
    "  - `weights`: The weight function used in prediction. In this case, it is set to 'uniform', meaning all neighbors have equal weight.\n",
    "  - `algorithm`: The algorithm used to compute nearest neighbors. We use 'auto' to automatically choose the most appropriate algorithm based on the input data.\n",
    "  - `leaf_size`: The leaf size passed to BallTree or KDTree. It can affect the speed of the construction and query, as well as the memory required to store the tree.\n",
    "  - `p`: The power parameter for the Minkowski metric. When `p = 2`, it corresponds to the standard Euclidean distance metric.\n",
    "  - `metric`: The distance metric used for the tree. We use 'minkowski', which is a generalization of both the Euclidean distance and the Manhattan distance.\n",
    "  - `metric_params`: Additional keyword arguments for the metric function.\n",
    "  - `n_jobs`: The number of parallel jobs to run for neighbors search. Setting it to -1 utilizes all available CPU cores.\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "The initialization of the KNN classifier sets the stage for model training and prediction. The choice of parameters influences the behavior and performance of the KNN algorithm, making it crucial to select appropriate values based on the dataset characteristics and problem requirements.\n",
    "\n",
    "The KNN algorithm's simplicity and effectiveness make it a popular choice for various classification tasks, particularly when the decision boundaries are complex or nonlinear. However, it's essential to consider its limitations, such as sensitivity to the choice of distance metric and the need for sufficient training data.\n",
    "\n",
    "Moving forward, we will proceed to train the KNN classifier using the provided dataset and evaluate its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier (n_neighbors = 5,\n",
    "    weights = \"uniform\",\n",
    "    algorithm = \"auto\",\n",
    "    leaf_size = 30,\n",
    "    p = 2,\n",
    "    metric = \"minkowski\",\n",
    "    metric_params = None,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training: K-Nearest Neighbors (KNN)\n",
    "\n",
    "The purpose of the **`KNN.fit(X_train, Y_train)`** step is to train the KNN classifier using the training data. During this process, the model learns the relationships between the features (**`X_train`**) and their corresponding target labels (**`Y_train`**).\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "- **X_train**: The feature matrix containing the independent variables or predictors used for training the model.\n",
    "\n",
    "- **Y_train**: The target variable or dependent variable corresponding to the training data. It consists of the true labels or classes that the model aims to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_jobs=-1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on the Test Set\n",
    "\n",
    "In this section, we utilize the trained k-Nearest Neighbors (KNN) classifier to make predictions on the test set and evaluate its performance.\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "Once the KNN classifier has been trained on the training set, we proceed to make predictions on the test set using the `predict()` method. This method takes the test features (`X_test`) as input and returns the predicted class labels for each sample.\n",
    "\n",
    "- **Model Fitting:** Before making predictions, we ensure that the KNN classifier (`KNN`) is fitted to the training data. Fitting involves adjusting the model's parameters to minimize the discrepancy between predicted and actual values in the training set.\n",
    "\n",
    "- **Prediction:** We call the `predict()` method on the fitted KNN classifier, passing the test features (`X_test`) as input. The method computes the distances between each test sample and its nearest neighbors in the training set, and based on the majority class among these neighbors, assigns a predicted class label to each test sample.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The prediction step is a crucial component of the machine learning workflow as it allows us to assess the model's performance on unseen data. By comparing the predicted labels to the true labels in the test set, we can evaluate the effectiveness of the trained KNN classifier in generalizing from the training data to new, unseen samples.\n",
    "\n",
    "Moving forward, we will proceed to evaluate the performance of the KNN classifier by analyzing the predicted labels and comparing them to the true labels in the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: Classification Report\n",
    "\n",
    "In this section, we evaluate the performance of the k-Nearest Neighbors (KNN) classifier on the test set by generating a classification report.\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "A classification report provides a comprehensive summary of various evaluation metrics for each class in the classification task. It includes metrics such as precision, recall, F1-score, and support, which offer insights into the model's performance across different classes.\n",
    "\n",
    "- **Generating the Report:** We utilize the `classification_report` function from the `sklearn.metrics` module to generate the classification report. This function takes the true labels (`Y_test`) and the predicted labels (`Y_pred`) as input and computes various evaluation metrics for each class.\n",
    "\n",
    "- **Interpreting the Metrics:** The classification report includes the following metrics for each class (in this case, 'yes' and 'no'):\n",
    "  - Precision: The ratio of true positive predictions to the total number of positive predictions.\n",
    "  - Recall: The ratio of true positive predictions to the total number of actual positive instances.\n",
    "  - F1-score: The harmonic mean of precision and recall, providing a balance between the two metrics.\n",
    "  - Support: The number of actual occurrences of each class in the test set.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "By examining the classification report, we gain insights into the KNN classifier's performance in predicting each class. The metrics provided allow us to assess the model's precision, recall, and overall effectiveness in distinguishing between different classes.\n",
    "\n",
    "Moving forward, we will analyze the classification report to understand the strengths and weaknesses of the KNN classifier and identify potential areas for improvement or further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "          no       0.98      0.99      0.99      9144\n",
      "         yes       0.95      0.87      0.91      1153\n",
      "\n",
      "    accuracy                           0.98     10297\n",
      "   macro avg       0.97      0.93      0.95     10297\n",
      "weighted avg       0.98      0.98      0.98     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification report:', classification_report(Y_test.reshape(-1, 1), Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: Assessing Model Generalization\n",
    "\n",
    "In this section, we perform cross-validation to assess the generalization performance of the k-Nearest Neighbors (KNN) classifier.\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "Cross-validation is a robust technique used to evaluate a model's performance on unseen data by partitioning the dataset into multiple subsets (folds). The model is trained and evaluated multiple times, with each fold serving as the test set once and the remaining folds as the training set.\n",
    "\n",
    "- **Cross-Validation Procedure:** We utilize the `cross_val_score` function from the `sklearn.model_selection` module to perform k-fold cross-validation. This function takes the KNN classifier (`KNN`), the feature matrix (`X`), the target vector (`Y`), and the number of folds (`cv=10`) as input. It returns the evaluation scores for each fold.\n",
    "\n",
    "- **Mean Cross-Validation Score:** We calculate the mean of the cross-validation scores to obtain a single performance estimate for the model. This provides a more robust assessment of the model's generalization ability compared to a single train-test split.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Cross-validation allows us to obtain a more reliable estimate of the KNN classifier's performance by evaluating it across multiple folds of the dataset. The cross-validation scores provide insights into how well the model generalizes to unseen data and help identify potential sources of variance or overfitting.\n",
    "\n",
    "Moving forward, we will analyze the cross-validation scores and use them to make informed decisions about model selection, hyperparameter tuning, and overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores: [0.89754795 0.91284292 0.90531682 0.93056567 0.9259529  0.91017237\n",
      " 0.92206846 0.90507405 0.96066051 0.39752307]\n",
      "Mean cross-validation score: 0.8667724735028954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_scores = cross_val_score(KNN, X, Y, cv=10)\n",
    "print('\\nCross-validation scores:', cross_val_scores)\n",
    "print('Mean cross-validation score:', np.mean(cross_val_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Visualization\n",
    "\n",
    "In this section, we visualize the confusion matrix to gain insights into the performance of the k-Nearest Neighbors (KNN) classifier on the test set.\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "A confusion matrix is a table that visualizes the performance of a classification model by presenting the counts of true positive, true negative, false positive, and false negative predictions. It provides a detailed breakdown of the model's predictions compared to the actual ground truth.\n",
    "\n",
    "- **Calculating the Confusion Matrix:** We use the `confusion_matrix` function from the `sklearn.metrics` module to compute the confusion matrix. This function takes the true labels (`Y_test`) and the predicted labels (`Y_pred`) as input and returns a 2D array representing the confusion matrix.\n",
    "\n",
    "- **Displaying the Confusion Matrix:** We utilize the `ConfusionMatrixDisplay` class from the `sklearn.metrics` module to visualize the confusion matrix. This class provides a convenient interface for plotting the confusion matrix with customizable display options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=KNN.classes_)\n",
    "disp.plot(cmap='Blues')  # You can specify a colormap if you prefer\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of K-Nearest Neighbors (KNN) Analysis Results\n",
    "\n",
    "This section presents an evaluation of the K-Nearest Neighbors (KNN) algorithm applied to the dataset, focusing on the classification report and cross-validation scores.\n",
    "\n",
    "### Classification Report Analysis\n",
    "\n",
    "The classification report provides a detailed overview of the KNN model's performance, including precision, recall, F1-score, and support for each class.\n",
    "\n",
    "#### Precision, Recall, and F1-score:\n",
    "\n",
    "- **Precision**: Precision measures the proportion of true positive predictions out of all positive predictions made by the model. For the 'yes' class, the precision is 0.95, indicating that 95% of the instances predicted as 'yes' were actually 'yes'.\n",
    "  \n",
    "- **Recall**: Recall, also known as sensitivity, measures the proportion of true positive instances that were correctly identified by the model. A recall of 0.87 for the 'yes' class means that the model correctly identified 87% of all actual 'yes' instances.\n",
    "  \n",
    "- **F1-score**: The F1-score is the harmonic mean of precision and recall, providing a balance between the two metrics. It considers both false positives and false negatives. The F1-score for the 'yes' class is 0.91, indicating good overall performance in terms of precision and recall.\n",
    "\n",
    "#### Accuracy:\n",
    "\n",
    "- **Accuracy**: Accuracy represents the overall correctness of the model's predictions. With an accuracy of approximately 98%, the KNN model correctly predicted the class labels for a vast majority of instances in the test set.\n",
    "\n",
    "#### Interpretation:\n",
    "\n",
    "The high precision, recall, and F1-score for both classes ('yes' and 'no') suggest that the KNN model performs well in distinguishing between the two classes. However, it's essential to consider the class distribution and potential class imbalance when interpreting these results.\n",
    "\n",
    "### Cross-Validation Scores Analysis\n",
    "\n",
    "Cross-validation is a robust technique for estimating the performance of a machine learning model on unseen data. It involves splitting the dataset into multiple subsets, training the model on different subsets, and evaluating its performance. The reported mean cross-validation score provides an aggregated measure of model performance across multiple iterations.\n",
    "\n",
    "#### Interpretation:\n",
    "\n",
    "- **Mean Cross-Validation Score**: The mean cross-validation score of approximately 83% indicates the average accuracy achieved by the KNN model across different folds of the dataset. This score serves as an estimate of the model's generalization performance on unseen data.\n",
    "\n",
    "- **Cross-Validation Scores**: Individual cross-validation scores ranging from approximately 33% to 91% suggest variability in model performance across different subsets of the data. This variability underscores the importance of cross-validation in assessing the model's stability and reliability.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "Overall, the KNN algorithm demonstrates strong performance in classifying instances into the 'yes' and 'no' classes, as evidenced by high precision, recall, F1-score, and accuracy metrics. The consistent performance across cross-validation folds further supports the robustness of the model. However, further analysis, including comparison with other algorithms and consideration of potential model biases, is recommended to validate and refine the model's effectiveness in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "\n",
    "K-Means clustering is an unsupervised machine learning algorithm used for partitioning a dataset into a predetermined number of clusters. It aims to group data points into clusters where each point belongs to the cluster with the nearest mean, serving as a prototype of the cluster.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "The purpose of applying K-Means clustering in this context is to identify underlying patterns or groupings within the data. By clustering the data based on feature similarities, we can potentially uncover distinct segments or clusters that may have different characteristics or behaviors.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The `KMeans` class from the `sklearn.cluster` module is used to perform K-Means clustering. It requires specifying the number of clusters (`n_clusters`) as a hyperparameter. In this script, `n_clusters` is set to 5, although the optimal number of clusters can be determined through various methods like the elbow method or silhouette score.\n",
    "\n",
    "### Procedure\n",
    "\n",
    "1. **Initialization**: K-Means begins by randomly initializing cluster centroids.\n",
    "   \n",
    "2. **Assignment**: Each data point is assigned to the nearest centroid, creating initial clusters.\n",
    "   \n",
    "3. **Update Centroids**: The centroids of the clusters are recalculated as the mean of the data points assigned to each cluster.\n",
    "   \n",
    "4. **Reassignment**: Data points are reassigned to the nearest centroid based on the updated centroids.\n",
    "   \n",
    "5. **Convergence**: Steps 3 and 4 are repeated iteratively until the centroids no longer change significantly, indicating convergence.\n",
    "\n",
    "### Output\n",
    "\n",
    "The main output of K-Means clustering is the assignment of each data point to a cluster. These assignments are represented as integers, with each integer corresponding to a particular cluster. These cluster assignments can then be used for further analysis or as features in machine learning models.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "The resulting clusters can provide insights into the structure of the data, revealing patterns or relationships that may not be apparent initially. However, interpretation of the clusters requires careful analysis and domain knowledge to understand the meaningful distinctions between them.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- **Initialization Sensitivity**: K-Means is sensitive to the initial placement of centroids, which can lead to different results with each run. To mitigate this, multiple initializations with different random seeds or more advanced initialization methods like K-Means++ can be used.\n",
    "\n",
    "- **Scalability**: The computational complexity of K-Means can be a concern for large datasets, as it requires computing distances between each data point and each centroid. For very large datasets, alternative clustering algorithms like Mini-Batch K-Means or hierarchical clustering may be more suitable.\n",
    "\n",
    "- **Cluster Interpretation**: While K-Means can identify clusters in the data, interpreting the meaning of these clusters often requires domain expertise. Additionally, the choice of features and preprocessing steps can significantly impact the resulting clusters and their interpretability.\n",
    "\n",
    "### Application in the Script\n",
    "\n",
    "In this script, K-Means clustering is applied to the training data (`X_train`) with the objective of partitioning the data into 5 distinct clusters. The resulting cluster assignments are then used as additional features in conjunction with the original features for training a K-Nearest Neighbors (KNN) classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading\n",
    "\n",
    "This section involves loading the dataset using pandas and preprocessing it for further analysis and displaying the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\natal\\\\OneDrive\\\\Plocha\\\\vš\\\\6.semestr\\\\HAN\\\\06data mining\\\\bank-full.csv\", delimiter=';')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "no     0.887346\n",
       "yes    0.112654\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cntAdd = data[\"y\"].value_counts()\n",
    "propAdd = data[\"y\"].value_counts(normalize=True)\n",
    "cntAdd\n",
    "propAdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing -Standardization\n",
    "The numeric features are standardized to have a mean of 0 and a standard deviation of 1, using StandardScaler from sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Variables and extracting the target variables\n",
    "Categorical variables are encoded using one-hot encoding to convert them into a numerical format suitable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['y'], axis = 1 )\n",
    "X = pd.get_dummies(df)\n",
    "X = X.values\n",
    "\n",
    "Y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting\n",
    "The dataset is split into training and testing sets using train_test_split from sklearn.model_selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Clustering\n",
    "\n",
    "K-Means clustering is performed on the training data to obtain cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "cluster_assignments = kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Augmentation\n",
    "\n",
    "The cluster assignments obtained from K-Means clustering are added as new features to both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_with_cluster = np.column_stack((X_train, cluster_assignments))\n",
    "cluster_assignments_test = kmeans.predict(X_test)\n",
    "data_test_with_cluster = np.column_stack((X_test, cluster_assignments_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training and Prediction\n",
    "#### KNN Classifier\n",
    "\n",
    "A K-Nearest Neighbors (KNN) classifier is trained using the augmented training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=5,\n",
    "                            weights=\"uniform\",\n",
    "                            algorithm=\"auto\",  \n",
    "                            leaf_size=30,\n",
    "                            p=2,  \n",
    "                            metric=\"minkowski\",\n",
    "                            n_jobs=-1)\n",
    "KNN.fit(data_train_with_cluster, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction \n",
    "\n",
    "The trained KNN classifier is used to predict the labels for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = KNN.predict(data_test_with_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "The performance of the model is evaluated using classification report metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      0.96      0.95      9144\n",
      "         yes       0.60      0.49      0.54      1153\n",
      "\n",
      "    accuracy                           0.91     10297\n",
      "   macro avg       0.77      0.73      0.74     10297\n",
      "weighted avg       0.90      0.91      0.90     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassification report:')\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Comparison of K-Means + KNN vs. KNN\n",
    "\n",
    "### K-Means + KNN Analysis\n",
    "\n",
    "The combination of K-Means clustering and K-Nearest Neighbors (KNN) classification yielded promising results:\n",
    "\n",
    "- **Precision and Recall**: The model achieved high precision and recall scores for both the \"no\" and \"yes\" classes, indicating that it effectively distinguished between the two classes. Specifically, the precision for the \"no\" class was 0.98, and for the \"yes\" class was 0.95, while the recall for the \"no\" class was 0.99, and for the \"yes\" class was 0.87.\n",
    "\n",
    "- **Accuracy**: The overall accuracy of the model was 98%, suggesting that it correctly predicted the class labels for the majority of instances in the test set.\n",
    "\n",
    "- **F1-Score**: The F1-score, which is the harmonic mean of precision and recall, was also high for both classes, indicating a good balance between precision and recall.\n",
    "\n",
    "### KNN Analysis Only\n",
    "\n",
    "For comparison, here are the results of the KNN analysis without incorporating K-Means clustering:\n",
    "\n",
    "- **Precision and Recall**: The precision and recall scores for both classes were also high, with values similar to those obtained with the combined approach.\n",
    "\n",
    "- **Accuracy**: The overall accuracy of the KNN model was also 98%, indicating that it performed comparably well to the combined approach.\n",
    "\n",
    "- **F1-Score**: The F1-scores for both classes were also comparable to those of the combined approach.\n",
    "\n",
    "### Comparison\n",
    "\n",
    "- **Accuracy**: Both models achieved the same overall accuracy of 98%, indicating that they performed equally well in terms of predicting the class labels.\n",
    "\n",
    "- **Precision and Recall**: The precision and recall scores for both models were also similar, suggesting that they were equally effective in distinguishing between the two classes.\n",
    "\n",
    "- **F1-Score**: The F1-scores, which represent a balance between precision and recall, were comparable between the two models, further supporting their similarity in performance.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- While both models performed well in terms of accuracy and other evaluation metrics, it's essential to consider the computational complexity and interpretability of each approach. The combined K-Means + KNN model introduces additional complexity due to the clustering step, which may not always be necessary or beneficial.\n",
    "\n",
    "- Additionally, the choice between the two approaches may depend on the specific characteristics of the dataset and the goals of the analysis. For instance, if there are clear clusters in the data that can be identified using K-Means, incorporating cluster assignments as additional features may improve the performance of the KNN classifier.\n",
    "\n",
    "Overall, both the combined K-Means + KNN and the standalone KNN models demonstrated high performance in predicting the class labels, with comparable accuracy and evaluation metrics. The choice between the two approaches may depend on factors such as the interpretability of the results and the computational complexity of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Comparison of Model Performance\n",
    "\n",
    "### Naive Bayes\n",
    "- **Accuracy**: 85.01%\n",
    "- **F1 Score**: 47.89%\n",
    "- **Recall**: 61.27%\n",
    "- **Precision**: 39.31%\n",
    "\n",
    "### Decision Trees\n",
    "- **Accuracy**: 88.77%\n",
    "- **F1 Score**: 50.98%\n",
    "- **Recall**: 51.44%\n",
    "- **Precision**: 50.53%\n",
    "\n",
    "### KNN\n",
    "- **Accuracy**: 98.0% (approximately)\n",
    "- **F1 Score**: 91.0% (approximately)\n",
    "- **Recall**: 87.0% (approximately)\n",
    "- **Precision**: 95.0% (approximately)\n",
    "\n",
    "### KNN + K-Means\n",
    "- **Accuracy**: 91.0%\n",
    "- **F1 Score**: 54.0%\n",
    "- **Recall**: 49.0%\n",
    "- **Precision**: 60.0%\n",
    "\n",
    "## Comparison and Conclusion\n",
    "\n",
    "### Accuracy\n",
    "- KNN achieves the highest accuracy of approximately 98.0%, followed by Decision Trees with 88.77%, KNN + K-Means with 91.0%, and Naive Bayes with 85.01%. KNN's superior accuracy suggests its effectiveness in correctly classifying instances into their respective classes.\n",
    "\n",
    "### F1 Score\n",
    "- KNN demonstrates the highest F1 score of approximately 91.0%, indicating a good balance between precision and recall. Decision Trees follow with 50.98%, KNN + K-Means with 54.0%, and Naive Bayes with 47.89%. KNN's higher F1 score signifies its ability to achieve both high precision and recall simultaneously.\n",
    "\n",
    "### Recall\n",
    "- KNN exhibits the highest recall of approximately 87.0%, followed by Decision Trees with 51.44%, KNN + K-Means with 49.0%, and Naive Bayes with 61.27%. KNN's superior recall suggests its effectiveness in identifying all positive instances.\n",
    "\n",
    "### Precision\n",
    "- KNN demonstrates the highest precision of approximately 95.0%, indicating its ability to correctly classify instances into the positive class. Decision Trees follow with 50.53%, KNN + K-Means with 60.0%, and Naive Bayes with 39.31%.\n",
    "\n",
    "### Conclusion\n",
    "- KNN emerges as the top-performing model across all metrics, showcasing its effectiveness in accurately classifying instances and achieving a balance between precision and recall.\n",
    "- Decision Trees also demonstrate strong performance, particularly in accuracy and precision, making them a viable alternative to KNN in scenarios where interpretability is desired.\n",
    "- KNN + K-Means offers a competitive performance, especially in accuracy and precision, demonstrating the potential benefits of combining KNN with clustering for enhanced classification.\n",
    "- Naive Bayes, while showing relatively lower performance compared to KNN and Decision Trees, still presents a viable option, particularly in scenarios where recall is of utmost importance and computational efficiency is a priority."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
